# Vibe Science v6.0 — Architectural Blueprint

**Codename:** NEXUS (Networked Enforcement eXecution Unified System)
**Autori:** Vibe Science Contributors + Claude Code (Opus 4.6)
**Data:** 20 febbraio 2026
**Input:** Blueprint v5.0 IUDEX, Blueprint v5.5 ORO, Blueprint ORO-PHOTONICS, Post-mortem CP+CRISPR run, claude-mem v10.3.1 reverse engineering, myBrAIn v1.1 analysis, brainstorming session v6.0
**Status:** IMPLEMENTATION COMPLETE — verified 2026-02-21
**Relazione con v5.5:** TRASFORMATIVA. v6.0 cambia la natura del prodotto: da skill (prompt) a plugin (codice + prompt). Tutta la metodologia v5.5 resta invariata. L'infrastruttura che la sostiene diventa architetturalmente enforceable.

---

## 1. Executive Summary

### Il problema fondamentale

v5.5 ORO ha identificato 12 errori con 7 cause radice nel run CRISPR e ha progettato 5 nuovi sottosistemi + 7 potenziamenti per coprirli. Ma v5.5 ha un'onesta ammissione nel suo stesso blueprint (Sezione 13):

> **4 su 7 sottosistemi v5.5 dipendono dal comportamento dell'agent — sono bypassabili via prompt.**

| Sottosistema | Architecture-enforced? | Bypassabile? |
|-------------|----------------------|-------------|
| DQ Gates (soglie numeriche) | **SI** | No — un numero matcha o non matcha |
| SSOT sync_check | **SI** | No — confronto automatico |
| Silent Observer | **SI** | No — daemon indipendente |
| VibeBrAIn recall | No | **SI** — agent puo' non chiamare recall |
| Research Spine | No | **SI** — agent puo' scrivere entry incomplete |
| R2 INLINE | No | **SI** — in SOLO mode e' auto-review |
| DD0 Gate | No | **SI** — agent puo' documentare male |

v5.5 stessa suggerisce: "Full enforcement richiederebbe un sistema esterno — candidato per v6.0."

### La soluzione: da Skill a Plugin

Una **skill** e' un prompt. Non esegue codice. Non ha stato persistente. Non puo' bloccare un agent che decide di ignorarla.

Un **plugin** ha:
- **Hooks** — codice che si esegue PRIMA e DOPO ogni azione dell'agent, con exit code 2 = BLOCK
- **Database** — stato persistente cross-sessione (SQLite + sqlite-vec)
- **Worker** — processo leggero per operazioni async (embedding vettoriale)
- **Permessi** — puo' identificare l'agent (ruolo TEAM) e bloccare azioni non autorizzate

**Cosa cambia:**

| Aspetto | v5.5 (Skill) | v6.0 (Plugin) |
|---------|-------------|---------------|
| Gate enforcement | "Per favore controlla" (prompt) | Exit code 2 = BLOCKED (codice) |
| Memory | File flat (.md/.json) + ChromaDB opzionale | SQLite + sqlite-vec integrato, sempre attivo |
| R2 permission | "R2 non deve scrivere CLAIM-LEDGER" (convenzione) | Hook PostToolUse: se agent=R2 e file=CLAIM-LEDGER → EXIT 2 |
| Logbook | "Scrivi nel Research Spine" (istruzione) | Hook auto-log: ogni azione significativa → DB entry |
| Cross-sessione | Nessuna memoria strutturata | Narrative summary + vector embeddings + claim history |
| Auto-miglioramento | Nessuno | R2 calibration loop, researcher pattern recognition |
| Installazione | Copia file → leggi prompt | 3 comandi → tutto funziona |

### Cosa NON cambia (invarianti da v5.0 + v5.5)

- Le **10 Leggi Immutabili** restano identiche
- L'architettura **OTAE-Tree** resta il cuore del loop
- **R2 Ensemble** (4 reviewer), **SFI**, **BFP**, **R3 Judge** restano
- Tutti i **34 gate** (27 v5.0 + 7 v5.5) restano — enforcement diventa reale
- **Agent Teams** (SOLO/TEAM) resta il modello di runtime
- I **12 schema JSON** restano read-only
- I **domain-specific blueprints** (CRISPR, Photonics) restano come reference

### Il principio architetturale

> **Skill DENTRO Plugin. Il plugin avvolge la skill, non la sostituisce.**

La metodologia (OTAE, R2, gates, brainstorm) vive nei prompt — e' flessibile, domain-agnostic, adattabile.
L'infrastruttura (memoria, enforcement, tracking, permessi) vive nel codice — e' rigida, affidabile, non bypassabile.

Il plugin e' il **corpo** (struttura, muscoli, sistema nervoso).
La skill e' la **mente** (ragionamento, strategia, creativita').

---

## 2. Lineage e Contesto

### Evoluzione della piattaforma

| Versione | Codename | Tipo | Innovazione chiave | Gate | Schema |
|----------|----------|------|-------------------|------|--------|
| v3.5 | TERTIUM DATUR | Skill | R2 adversariale, OTAE-Tree | ~20 | 0 |
| v4.0 | ARBOR VITAE | Skill | Tree search, 7 node types | ~25 | 0 |
| v4.5 | ARBOR VITAE (Pruned) | Skill | R2 Ensemble (4 reviewer, 6 modi), Red Flag Checklist | 25 | 0 |
| v5.0 | IUDEX | Skill | SFI, BFP, R3 Judge, Schema-Validated Gates | 27 | 9 |
| v5.5 | ORO | Skill | DQ Gates, Research Spine, VibeBrAIn, SSOT, Silent Observer, R2 INLINE | 34 | 12 |
| **v6.0** | **NEXUS** | **Plugin** | **Infrastructure enforcement, persistent memory, auto-calibration, TEAM permissions** | **34** | **12** |
| *Photonics* | *ORO-PHOTONICS* | *Skill fork* | *R2-Physics, Expert Knowledge Injection, HE0-HE3* | *36* | *12* |

### Analisi dei predecessori (input per v6.0)

**claude-mem v10.3.1** (reverse engineered 2026-02-20):
- Architecture: 5 lifecycle hooks + worker service (Express, port 37777) + SQLite + ChromaDB + SDK Agent per compressione
- Punti di forza: progressive disclosure (3-layer), narrative summaries, MCP search tools, privacy controls
- Punti di debolezza per noi: domain-agnostic (coding memory), overhead eccessivo (Express server, Web UI, SDK Agent spawn)
- Pattern adottati: hook lifecycle mapping, progressive disclosure, narrative summary at Stop
- Pattern scartati: Express server (overkill), SDK Agent spawn (lento/costoso), Web UI (non serve per CLI), full Chroma (200 MB)

**myBrAIn v1.1** (analizzato 2026-02-19):
- Architecture: MCP server + ChromaDB + SilentObserver daemon
- Pattern adottati in v5.5: RECALL→CODE→MEMORIZE, conflict detection, audit methodology
- Lezione chiave: "per una skill aggiungere un database vettoriale e' inutile — una skill sono prompt, non codice"
- Questa lezione ha motivato il passaggio a plugin

### La domanda chiave del brainstorming

> "Cosa cambia con claude-mem rispetto a myBrAIn? In che modo evolvere in plugin ci puo' aiutare?"

**Risposta:**
- myBrAIn = aggiungere un database a una skill → impossibile (skill non esegue codice)
- claude-mem = aggiungere infrastruttura domain-agnostic a un agent → possibile
- **v6.0 = aggiungere infrastruttura domain-agnostic a un agent che gia' ha la metodologia scientifica migliore dell'ecosistema**

---

## 3. Architettura v6.0: Opzione B (Equilibrata)

### Perche' Opzione B

Durante il brainstorming sono state valutate 3 opzioni:

| Opzione | Descrizione | Pro | Contro |
|---------|-------------|-----|--------|
| **A: Lightweight** | Solo hooks, no worker, no vector search | Minima complessita' | Niente embedding semantico, niente async |
| **B: Equilibrata** | Hooks + SQLite/sqlite-vec + daemon leggero per embedding | Balance complessita'/potenza | Daemon da gestire (ma leggero) |
| **C: Full claude-mem** | Express server + full Chroma + Web UI + SDK Agent | Massima potenza | 200 MB deps, overhead, over-engineering |

**Scelta: Opzione B.** Motivazione:
1. sqlite-vec (~1 MB) al posto di Chroma (~200 MB) — stesso risultato, 200x piu' leggero
2. Single database (SQLite) — no coordinamento tra sistemi
3. Daemon leggero SOLO per embedding asincrono — tutto il resto negli hooks direttamente
4. Niente Express/Web UI — CLI-first (Claude Code e' CLI)

### Directory Structure

```
vibe-science-v6.0/
├── .claude-plugin/
│   └── plugin.json                    # Plugin manifest (nome, versione, hooks, setup)
│
├── plugin/                             # INFRASTRUTTURA (codice)
│   ├── hooks/
│   │   └── hooks.json                  # Hook definitions (5 lifecycle + 1 setup)
│   ├── scripts/
│   │   ├── setup.js                    # Auto-install: Bun, SQLite, sqlite-vec, directory creation
│   │   ├── session-start.js            # SessionStart: context injection, recall, observer alerts
│   │   ├── prompt-submit.js            # UserPromptSubmit: agent identification, permission check
│   │   ├── post-tool-use.js            # PostToolUse: gate enforcement, permission enforcement, auto-log
│   │   ├── stop.js                     # Stop: narrative summary, session export, claim sync
│   │   └── worker-embed.js             # Daemon leggero per embedding async (Bun)
│   ├── db/
│   │   ├── schema.sql                  # Database schema completo
│   │   └── migrations/                 # Future schema migrations
│   └── lib/
│       ├── context-builder.js          # Progressive disclosure engine
│       ├── gate-engine.js              # Gate enforcement logic
│       ├── permission-engine.js        # TEAM mode permission enforcement
│       ├── narrative-engine.js         # Session summary generator
│       └── vec-search.js              # sqlite-vec wrapper per ricerca semantica
│
├── skill/                              # METODOLOGIA (prompt) — tutto v5.5 invariato
│   ├── SKILL.md                        # v5.5 ORO completo (1278+ righe)
│   ├── CLAUDE.md                       # v5.5 ORO constitution
│   ├── protocols/                      # 29 protocolli (21 v5.0 + 8 v5.5)
│   │   ├── seeded-fault-injection.md
│   │   ├── judge-agent.md
│   │   ├── blind-first-pass.md
│   │   ├── schema-validation.md
│   │   ├── circuit-breaker.md
│   │   ├── research-spine.md           # v5.5
│   │   ├── data-quality-gates.md       # v5.5
│   │   ├── ssot-autogen.md             # v5.5
│   │   ├── r2-inline.md                # v5.5
│   │   ├── literature-precheck.md      # v5.5
│   │   ├── data-dictionary.md          # v5.5
│   │   ├── design-compliance.md        # v5.5
│   │   ├── vibebrain-integration.md    # v5.5
│   │   └── ... (altri protocolli v5.0)
│   ├── gates/
│   │   └── gates.md                    # 34 gate (27 v5.0 + 7 v5.5)
│   ├── schemas/                        # 12 JSON Schema (9 v5.0 + 3 v5.5), READ-ONLY
│   └── assets/                         # fault-taxonomy.yaml, judge-rubric.yaml
│
├── blueprints/                         # REFERENCE DOCUMENTS (domain-specific)
│   ├── v5.0-IUDEX-BLUEPRINT.md
│   ├── v5.5-ORO-BLUEPRINT.md
│   ├── v6.0-NEXUS-BLUEPRINT.md         # Questo documento
│   └── PHOTONICS-BLUEPRINT.md          # ORO-PHOTONICS fork reference
│
├── README.md
└── package.json
```

### Principio di separazione

```
┌─────────────────────────────────────────────────────────┐
│                    PLUGIN (Codice)                        │
│                                                           │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌────────────┐ │
│  │  Hooks   │ │ Database │ │  Worker  │ │ Permission │ │
│  │(enforce) │ │ (persist)│ │(embed)   │ │  (TEAM)    │ │
│  └────┬─────┘ └────┬─────┘ └────┬─────┘ └─────┬──────┘ │
│       │            │            │              │         │
│       └────────────┼────────────┼──────────────┘         │
│                    │            │                         │
│                    ▼            ▼                         │
│              ┌──────────────────────┐                    │
│              │      SQLite DB       │                    │
│              │  + sqlite-vec        │                    │
│              │  (~/.vibe-science/)  │                    │
│              └──────────────────────┘                    │
│                                                           │
├───────────────────────────────────────────────────────────┤
│                     SKILL (Prompt)                        │
│                                                           │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌────────────┐ │
│  │   OTAE   │ │    R2    │ │  Gates   │ │ Brainstorm │ │
│  │  Tree    │ │ Ensemble │ │ (34 def) │ │  Engine    │ │
│  └──────────┘ └──────────┘ └──────────┘ └────────────┘ │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌────────────┐ │
│  │Evidence  │ │Serendip. │ │   SFI    │ │   R3       │ │
│  │ Engine   │ │ Engine   │ │   BFP    │ │  Judge     │ │
│  └──────────┘ └──────────┘ └──────────┘ └────────────┘ │
│                                                           │
│  SKILL.md + CLAUDE.md + 29 protocolli + 12 schema        │
│  + fault-taxonomy + judge-rubric                          │
│                                                           │
├───────────────────────────────────────────────────────────┤
│                   BLUEPRINTS (Reference)                  │
│                                                           │
│  Domain-specific knowledge + architettura di riferimento  │
│  CRISPR: v5.0-IUDEX, v5.5-ORO                           │
│  Photonics: ORO-PHOTONICS                                │
│  Loaded into context on demand (not always)               │
│                                                           │
└───────────────────────────────────────────────────────────┘
```

---

## 4. I 5 Lifecycle Hooks

### 4.0 Setup Hook (pre-lifecycle)

Eseguito una volta alla prima installazione e ad ogni aggiornamento.

```javascript
// plugin/scripts/setup.js

async function setup() {
    // 1. Check Node.js version (>= 18.0.0 required)
    const nodeVersion = process.versions.node;
    const [major] = nodeVersion.split('.').map(Number);
    if (major < 18) {
        return { status: 'error', error: `Node.js >= 18.0.0 required, found ${nodeVersion}` };
    }

    // 2. Detect Bun (optional) with fallback to npm
    const hasBun = await commandExists('bun');
    const pkgManager = hasBun ? 'bun' : 'npm';

    // 3. Create global directories
    const globalDir = path.join(os.homedir(), '.vibe-science');
    await fs.mkdir(path.join(globalDir, 'db'), { recursive: true });
    await fs.mkdir(path.join(globalDir, 'logs'), { recursive: true });

    // 4. Initialize SQLite database from schema.sql
    const dbPath = path.join(globalDir, 'db', 'vibe-science.db');
    const db = new Database(dbPath);
    await runMigrations(db, path.join(__dirname, '..', 'db'));

    // 5. Smart dependency install with marker file (.install-marker)
    //    Skips if marker exists and is < 24h old
    const markerPath = path.join(globalDir, '.install-marker');
    let depsInstalled = false;
    const markerAge = await getFileAge(markerPath);
    if (!markerAge || markerAge > 24 * 60 * 60 * 1000) {
        await exec(`${pkgManager} install`, { cwd: pluginDir });
        await fs.writeFile(markerPath, new Date().toISOString());
        depsInstalled = true;
    }

    // 6. Launch worker daemon with PID file (.worker.pid)
    const pidFile = path.join(globalDir, '.worker.pid');
    const workerPid = await launchWorkerDaemon(globalDir, pidFile);

    // 7. Check model status (@huggingface/transformers lazy loading)
    const modelStatus = await checkModelAvailability();

    return {
        status: 'ready',
        db_path: dbPath,
        worker_pid: workerPid,
        deps_installed: depsInstalled,
        node_version: nodeVersion,
        model_status: modelStatus   // 'cached' | 'pending_download' | 'error'
    };
}
```

**Dipendenze totali:** Node.js >= 18.0.0 (prerequisito Claude Code), sqlite-vec (~1 MB, bundled), `@huggingface/transformers` + `onnxruntime-node` (~23 MB quantized ONNX model). Bun opzionale (detected, fallback a npm). Nessuna dipendenza Python.

### 4.0.1 Worker Daemon e Embedding System

Il worker daemon (`worker-embed.js`) gestisce l'embedding asincrono della coda `embed_queue`. Usa `@huggingface/transformers` con modello quantizzato ONNX.

```javascript
// plugin/scripts/worker-embed.js

import { pipeline } from '@huggingface/transformers';

// ═══════════════════════════════════════════════════════
// LAZY MODEL LOADING
// ═══════════════════════════════════════════════════════

let embeddingPipeline = null;

async function loadModel() {
    if (!embeddingPipeline) {
        embeddingPipeline = await pipeline(
            'feature-extraction',
            'Xenova/all-MiniLM-L6-v2'    // ~23 MB quantized ONNX
        );
    }
    return embeddingPipeline;
}

// ═══════════════════════════════════════════════════════
// EMBEDDING FUNCTIONS
// ═══════════════════════════════════════════════════════

// Primary: real ML embedding via @huggingface/transformers
async function realEmbedding(text) {
    const pipe = await loadModel();
    const output = await pipe(text, { pooling: 'mean', normalize: true });
    return new Float32Array(output.data);  // Float32Array[384]
}

// Fallback: SHA-256 hash-based vector (deterministic, no model needed)
function simpleEmbedding(text) {
    const hash = crypto.createHash('sha256').update(text).digest();
    const vec = new Float32Array(384);
    for (let i = 0; i < 384; i++) {
        vec[i] = (hash[i % 32] / 255.0) * 2 - 1;  // normalize to [-1, 1]
    }
    return vec;
}

// Dispatcher: tries real, falls back to simple
async function embed(text) {
    try {
        return await realEmbedding(text);
    } catch (err) {
        log(`realEmbedding failed, using simpleEmbedding fallback: ${err.message}`);
        return simpleEmbedding(text);
    }
}

// ═══════════════════════════════════════════════════════
// BATCH PROCESSING (2-phase)
// ═══════════════════════════════════════════════════════

async function processBatch(db) {
    const pending = db.all(
        `SELECT id, text, metadata FROM embed_queue
         WHERE processed = 0 ORDER BY id LIMIT 50`
    );
    if (pending.length === 0) return 0;

    // Phase 1: Async embed (parallelizable)
    const embeddings = await Promise.all(
        pending.map(row => embed(row.text))
    );

    // Phase 2: Sync DB write (transactional)
    db.exec('BEGIN');
    for (let i = 0; i < pending.length; i++) {
        db.run(`INSERT INTO vec_memories (embedding, text, metadata, project_path, created_at)
                VALUES (?, ?, ?, ?, ?)`,
            embeddings[i], pending[i].text, pending[i].metadata,
            JSON.parse(pending[i].metadata)?.project_path || '',
            new Date().toISOString()
        );
        db.run(`UPDATE embed_queue SET processed = 1 WHERE id = ?`, pending[i].id);
    }
    db.exec('COMMIT');

    return pending.length;
}

// ═══════════════════════════════════════════════════════
// ASYNC TICK LOOP + DAILY LOG ROTATION
// ═══════════════════════════════════════════════════════

async function tick(db) {
    const processed = await processBatch(db);
    if (processed > 0) {
        log(`Processed ${processed} embeddings`);
    }
    // Daily log rotation
    rotateLogIfNeeded();
    // Schedule next tick
    setTimeout(() => tick(db), 5000);  // every 5 seconds
}
```

**Design rationale:** Il modello `Xenova/all-MiniLM-L6-v2` e' un quantized ONNX (~23 MB) caricato lazy al primo embedding. `realEmbedding()` produce un `Float32Array[384]` via `@huggingface/transformers`. Se il modello non e' disponibile (primo avvio, errore download), `simpleEmbedding()` fornisce un fallback deterministico basato su SHA-256. Il batch processing e' 2-phase: prima tutti gli embedding async, poi una transazione DB atomica. Il tick loop asincrono processa la coda ogni 5 secondi. Log rotation giornaliera previene crescita illimitata dei file di log.

### 4.1 SessionStart Hook

Eseguito all'inizio di ogni sessione Claude Code nel progetto.

```javascript
// plugin/scripts/session-start.js

async function onSessionStart({ session, project_path }) {
    const db = openDB();
    const sessionId = crypto.randomUUID();

    // 1. Registra sessione
    db.run(`INSERT INTO sessions (id, project_path, started_at) VALUES (?, ?, ?)`,
        sessionId, project_path, new Date().toISOString());

    // 2. PROGRESSIVE DISCLOSURE — Build context injection
    const context = buildContext(db, project_path, sessionId);

    // 3. Controlla alert Observer pendenti
    const alerts = db.all(`SELECT * FROM observer_alerts
        WHERE project_path = ? AND resolved = 0 ORDER BY level DESC`,
        project_path);

    // 4. Carica auto-calibration data per R2
    const r2Stats = loadR2CalibrationData(db, project_path);

    // 5. Inietta contesto nella sessione
    return {
        context: formatContextForInjection(context, alerts, r2Stats),
        sessionId
    };
}
```

**Output:** Stringa di contesto (~700 token) iniettata nel prompt di sistema. Contiene:
- Stato corrente del progetto (ultimo STATE.md)
- Ultime 3 decisioni/errori rilevanti (via vec search)
- Alert Observer non risolti
- R2 calibration hints ("nelle ultime 5 sessioni, R2 ha mancato: feature validation, terminology precision")

### 4.2 UserPromptSubmit Hook

Eseguito PRIMA che il prompt dell'utente venga processato dal modello.

```javascript
// plugin/scripts/prompt-submit.js

async function onUserPromptSubmit({ prompt, session_id, agent_role }) {
    const db = openDB();

    // 1. TEAM MODE — Identifica agent
    const role = identifyAgentRole(agent_role, prompt);
    // Possibili: 'lead', 'researcher', 'reviewer2', 'serendipity', 'experimenter', 'judge'

    // 2. Logga prompt nel database (per audit trail)
    db.run(`INSERT INTO prompt_log (session_id, agent_role, prompt_hash, timestamp)
            VALUES (?, ?, ?, ?)`,
        session_id, role, hashPrompt(prompt), new Date().toISOString());

    // 3. Context recall semantico (VibeBrAIn RECALL, ora infrastructure-enforced)
    const relevantMemories = vecSearch(db,
        prompt.substring(0, 500),  // primi 500 char come query
        { project_path: getProjectPath(), limit: 3 }
    );

    // 4. Inietta memorie rilevanti come contesto aggiuntivo
    if (relevantMemories.length > 0) {
        return {
            additionalContext: formatMemories(relevantMemories),
            agentRole: role
        };
    }

    return { agentRole: role };
}
```

**Differenza critica da v5.5:** In v5.5, `recall_context()` e' un'istruzione nel prompt — l'agent puo' non chiamarla. In v6.0, il recall avviene AUTOMATICAMENTE nel hook, prima che l'agent veda il prompt. L'agent riceve il contesto senza doverlo chiedere.

### 4.3 PostToolUse Hook

Il cuore del sistema di enforcement. Eseguito DOPO ogni utilizzo di tool da parte dell'agent.

```javascript
// plugin/scripts/post-tool-use.js

async function onPostToolUse({ tool_name, tool_input, tool_output, session_id, agent_role }) {
    const db = openDB();

    // ═══════════════════════════════════════════════════════
    // 1. GATE ENFORCEMENT (DQ1-DQ4, DC0, DD0, L-1)
    // ═══════════════════════════════════════════════════════

    if (tool_name === 'Edit' || tool_name === 'Write') {
        const filePath = tool_input.file_path;

        // Gate DQ4: Se modifica FINDINGS.md, verifica sync con JSON
        if (filePath.includes('FINDINGS') && filePath.endsWith('.md')) {
            const syncResult = runSyncCheck(filePath, findJsonSource(filePath));
            if (!syncResult.pass) {
                return {
                    exitCode: 2,  // BLOCK
                    stderr: `GATE DQ4 FAIL: ${syncResult.mismatches.length} numeri non matchano JSON.\n` +
                            syncResult.mismatches.map(m => `  ${m.number} in "${m.context}"`).join('\n')
                };
            }
        }

        // Gate enforcement: Se modifica CLAIM-LEDGER, verifica gates
        if (filePath.includes('CLAIM-LEDGER')) {
            const claimId = extractClaimId(tool_input.content || tool_input.new_string);
            if (claimId) {
                const gateResults = db.all(
                    `SELECT gate_id, status FROM gate_checks
                     WHERE claim_id = ? AND status = 'PASS'`, claimId
                );
                const required = getRequiredGatesForClaim(claimId);
                const missing = required.filter(g => !gateResults.find(x => x.gate_id === g));
                if (missing.length > 0) {
                    return {
                        exitCode: 2,
                        stderr: `GATE FAIL: ${missing.join(', ')} non passati per ${claimId}. ` +
                                `Fix first, re-gate, then continue.`
                    };
                }
            }
        }
    }

    // ═══════════════════════════════════════════════════════
    // 2. PERMISSION ENFORCEMENT (TEAM MODE)
    // ═══════════════════════════════════════════════════════

    if (agent_role) {
        const violation = checkPermission(agent_role, tool_name, tool_input);
        if (violation) {
            return {
                exitCode: 2,
                stderr: `PERMISSION DENIED: Agent ${agent_role} cannot ${violation.action}.\n` +
                        `Reason: ${violation.reason}\n` +
                        `Required role: ${violation.required_role}`
            };
        }
    }

    // ═══════════════════════════════════════════════════════
    // 3. AUTO-LOGGING (Research Spine, ora automatico)
    // ═══════════════════════════════════════════════════════

    const actionType = classifyAction(tool_name, tool_input, tool_output);
    if (actionType) {
        db.run(`INSERT INTO spine_entries
                (session_id, timestamp, action_type, tool_name, input_summary, output_summary, agent_role)
                VALUES (?, ?, ?, ?, ?, ?, ?)`,
            session_id,
            new Date().toISOString(),
            actionType,
            tool_name,
            summarizeInput(tool_input, 200),    // max 200 chars
            summarizeOutput(tool_output, 200),
            agent_role
        );

        // Queue per embedding async
        db.run(`INSERT INTO embed_queue (text, metadata, created_at)
                VALUES (?, ?, ?)`,
            `${actionType}: ${summarizeInput(tool_input, 500)}`,
            JSON.stringify({ session_id, action_type: actionType, agent_role }),
            new Date().toISOString()
        );
    }

    // ═══════════════════════════════════════════════════════
    // 4. OBSERVER CHECKS (Silent Observer, now in-hook)
    // ═══════════════════════════════════════════════════════

    // Check solo ogni N tool uses (non ad ogni singolo tool use — costo)
    const toolCount = db.get(`SELECT COUNT(*) as n FROM spine_entries
                              WHERE session_id = ?`, session_id).n;
    if (toolCount % 10 === 0) {
        const observerAlerts = runObserverChecks(getProjectPath());
        for (const alert of observerAlerts) {
            db.run(`INSERT INTO observer_alerts
                    (project_path, level, message, created_at)
                    VALUES (?, ?, ?, ?)`,
                getProjectPath(), alert.level, alert.message, new Date().toISOString()
            );
            if (alert.level === 'HALT') {
                return {
                    exitCode: 2,
                    stderr: `OBSERVER HALT: ${alert.message}`
                };
            }
        }
    }

    return { exitCode: 0 };
}
```

**Permission Matrix (TEAM Mode):**

```javascript
// plugin/lib/permission-engine.js

const PERMISSIONS = {
    researcher: {
        allow: ['Read', 'Write', 'Edit', 'Bash', 'Glob', 'Grep', 'WebSearch', 'WebFetch'],
        deny_files: [],  // puo' scrivere ovunque tranne R2 reports
        deny_patterns: ['05-reviewer2/*-report.yaml']
    },
    reviewer2: {
        allow: ['Read', 'Glob', 'Grep', 'WebSearch', 'WebFetch', 'Write', 'Edit'],
        deny_files: ['CLAIM-LEDGER.md'],  // NON puo' scrivere nel ledger
        deny_patterns: [],
        allow_write_only: ['05-reviewer2/']  // puo' scrivere SOLO nei suoi report
    },
    judge: {
        allow: ['Read', 'Glob', 'Grep'],
        deny_files: ['CLAIM-LEDGER.md', '05-reviewer2/*'],  // SOLO lettura
        allow_write_only: ['05-reviewer2/judge-reports/']
    },
    serendipity: {
        allow: ['Read', 'Glob', 'Grep', 'WebSearch', 'WebFetch', 'Write'],
        deny_files: ['CLAIM-LEDGER.md'],
        allow_write_only: ['SERENDIPITY.md']
    },
    lead: {
        allow: ['Read', 'Glob', 'Grep', 'Write', 'Edit', 'Task'],
        deny_files: [],  // lead puo' coordinare tutto
    },
    experimenter: {
        allow: ['Read', 'Write', 'Edit', 'Bash', 'Glob', 'Grep'],
        deny_files: ['CLAIM-LEDGER.md', '05-reviewer2/'],
    }
};
```

### 4.4 Stop Hook

Eseguito quando l'agent sta per terminare la sessione.

```javascript
// plugin/scripts/stop.js

async function onStop({ session_id, project_path }) {
    const db = openDB();

    // ═══════════════════════════════════════════════════════
    // 1. NARRATIVE SUMMARY (memoria narrata — il cuore)
    // ═══════════════════════════════════════════════════════

    const spineEntries = db.all(
        `SELECT * FROM spine_entries WHERE session_id = ? ORDER BY timestamp`,
        session_id
    );
    const claims = db.all(
        `SELECT * FROM claim_events WHERE session_id = ? ORDER BY timestamp`,
        session_id
    );
    const gates = db.all(
        `SELECT * FROM gate_checks WHERE session_id = ? ORDER BY timestamp`,
        session_id
    );

    // Genera summary narrativo strutturato (senza LLM — template-based)
    const summary = generateNarrativeSummary({
        entries: spineEntries,
        claims: claims,
        gates: gates,
        sessionId: session_id,
        projectPath: project_path
    });

    // Salva nel DB
    db.run(`UPDATE sessions SET
            narrative_summary = ?,
            ended_at = ?,
            total_actions = ?,
            claims_created = ?,
            claims_killed = ?,
            gates_passed = ?,
            gates_failed = ?
            WHERE id = ?`,
        summary.text,
        new Date().toISOString(),
        spineEntries.length,
        claims.filter(c => c.event_type === 'CREATED').length,
        claims.filter(c => c.event_type === 'KILLED').length,
        gates.filter(g => g.status === 'PASS').length,
        gates.filter(g => g.status === 'FAIL').length,
        session_id
    );

    // Queue summary per embedding
    db.run(`INSERT INTO embed_queue (text, metadata, created_at)
            VALUES (?, ?, ?)`,
        summary.text,
        JSON.stringify({ session_id, type: 'narrative_summary' }),
        new Date().toISOString()
    );

    // ═══════════════════════════════════════════════════════
    // 2. ENFORCEMENT CHECKS (v5.5 hooks mantenuti)
    // ═══════════════════════════════════════════════════════

    // Verifica che tutte le claims abbiano confounder harness o R2 review
    const unreviewedClaims = db.all(`
        SELECT claim_id FROM claim_events
        WHERE session_id = ?
        AND event_type = 'CREATED'
        AND claim_id NOT IN (
            SELECT claim_id FROM claim_events
            WHERE event_type IN ('R2_REVIEWED', 'KILLED', 'DISPUTED')
        )`, session_id);

    if (unreviewedClaims.length > 0) {
        return {
            exitCode: 2,
            stderr: `STOP BLOCKED: ${unreviewedClaims.length} claims senza R2 review: ` +
                    unreviewedClaims.map(c => c.claim_id).join(', ') +
                    `\nLAW 4: R2 is co-pilot. Review before stopping.`
        };
    }

    // ═══════════════════════════════════════════════════════
    // 3. EXPORT per .vibe-science/ (compatibilita' con resume)
    // ═══════════════════════════════════════════════════════

    // Aggiorna STATE.md con summary (LAW 7: resumability)
    await updateStateMdFromDB(db, session_id, project_path);

    return { exitCode: 0, narrative: summary.text };
}
```

**Narrative Summary Template (senza LLM):**

```javascript
function generateNarrativeSummary({ entries, claims, gates, sessionId }) {
    const sections = [];

    sections.push(`## Session ${sessionId.substring(0, 8)}`);
    sections.push(`**Duration:** ${entries.length} actions`);

    // Cosa e' stato fatto
    const actionCounts = countBy(entries, 'action_type');
    sections.push(`**Actions:** ${Object.entries(actionCounts).map(([k,v]) => `${k}(${v})`).join(', ')}`);

    // Claims
    if (claims.length > 0) {
        sections.push(`\n### Claims`);
        for (const c of groupBy(claims, 'claim_id')) {
            const latest = c.events[c.events.length - 1];
            sections.push(`- **${c.claim_id}**: ${latest.event_type} (confidence: ${latest.confidence || '?'})`);
            if (latest.narrative) sections.push(`  ${latest.narrative}`);
        }
    }

    // Gates
    const failedGates = gates.filter(g => g.status === 'FAIL');
    if (failedGates.length > 0) {
        sections.push(`\n### Gates Failed`);
        for (const g of failedGates) {
            sections.push(`- **${g.gate_id}**: ${g.message}`);
        }
    }

    // Errori/decisioni importanti
    const mistakes = entries.filter(e => e.action_type === 'BUG_FIX' || e.action_type === 'DESIGN_CHANGE');
    if (mistakes.length > 0) {
        sections.push(`\n### Corrections & Decisions`);
        for (const m of mistakes) {
            sections.push(`- [${m.action_type}] ${m.input_summary}`);
        }
    }

    return { text: sections.join('\n'), tokenEstimate: estimateTokens(sections.join('\n')) };
}
```

**Perche' senza LLM:** claude-mem usa un SDK Agent (spawn di Claude subprocess) per generare summaries. Questo costa token, richiede API key, e aggiunge latenza. Il nostro summary e' template-based: piu' veloce, zero costo, deterministico. I dati sono gia' strutturati nel DB — non serve un LLM per riassumerli.

### 4.5 hooks.json

```json
{
    "hooks": {
        "Setup": [
            {
                "name": "vibe-science-setup",
                "description": "Initialize Vibe Science database, directories, and worker",
                "script": "plugin/scripts/setup.js"
            }
        ],
        "SessionStart": [
            {
                "name": "vibe-science-context",
                "description": "Inject progressive context, observer alerts, R2 calibration",
                "script": "plugin/scripts/session-start.js"
            }
        ],
        "UserPromptSubmit": [
            {
                "name": "vibe-science-recall",
                "description": "Agent identification, semantic recall, permission context",
                "script": "plugin/scripts/prompt-submit.js"
            }
        ],
        "PostToolUse": [
            {
                "name": "vibe-science-enforce",
                "description": "Gate enforcement, permission enforcement, auto-log, observer",
                "script": "plugin/scripts/post-tool-use.js"
            }
        ],
        "Stop": [
            {
                "name": "vibe-science-stop",
                "description": "Narrative summary, claim review check, state export",
                "script": "plugin/scripts/stop.js"
            }
        ]
    }
}
```

### Mapping Hook → OTAE

```
OTAE Loop:                          Hook Coverage:

OBSERVE                             SessionStart: context injection, recall
  ├── Read STATE.md                 ← Auto-injected from DB
  ├── Identify stage                ← Auto-injected from DB
  ├── Check pending gates           ← Auto-injected from DB
  ├── recall_context()              ← UserPromptSubmit: auto recall (enforced)
  └── observer.check_alerts()       ← SessionStart: alerts from DB

THINK                               (No hook — agent reasoning, leave free)

ACT                                 PostToolUse: per ogni tool
  ├── DD0 (Data Dictionary)         ← PostToolUse: file pattern match
  ├── Execute action                ← PostToolUse: auto-log to spine_entries
  ├── DQ1 (Post-Extraction)         ← PostToolUse: trigger on feature files
  ├── DQ2 (Post-Training)           ← PostToolUse: trigger on model outputs
  └── DQ3 (Post-Calibration)        ← PostToolUse: trigger on CP results

EVALUATE                            PostToolUse: per ogni tool
  ├── Claim extraction              ← PostToolUse: auto-log claim_events
  ├── DQ4 (Post-Finding)            ← PostToolUse: FINDINGS.md sync check
  ├── R2 gate                       ← PostToolUse: permission enforcement
  └── Gate application              ← PostToolUse: gate enforcement

CHECKPOINT                          PostToolUse: periodic observer checks
  ├── R2 Co-Pilot Check             ← Permission: R2 can only write reports
  ├── DC0 (Design Compliance)       ← PostToolUse: phase change detection
  └── Serendipity sprint check      ← Auto-log in spine_entries

CRYSTALLIZE                         Stop hook
  ├── CLAIM-LEDGER sync             ← Stop: claim review check
  ├── TREE-STATE.json               ← Stop: state export
  ├── Narrative summary             ← Stop: auto-generated from DB
  └── VibeBrAIn MEMORIZE            ← Stop: embed queue processed
```

---

## 5. Database Schema

### 5.1 SQLite Schema

```sql
-- plugin/db/schema.sql

-- ═══════════════════════════════════════════════════════
-- CORE: Sessions and Actions
-- ═══════════════════════════════════════════════════════

CREATE TABLE sessions (
    id TEXT PRIMARY KEY,
    project_path TEXT NOT NULL,
    started_at TEXT NOT NULL,
    ended_at TEXT,
    narrative_summary TEXT,
    total_actions INTEGER DEFAULT 0,
    claims_created INTEGER DEFAULT 0,
    claims_killed INTEGER DEFAULT 0,
    gates_passed INTEGER DEFAULT 0,
    gates_failed INTEGER DEFAULT 0
);

CREATE TABLE spine_entries (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL REFERENCES sessions(id),
    timestamp TEXT NOT NULL,
    action_type TEXT NOT NULL,  -- DATA_LOAD, FEATURE_EXTRACTION, MODEL_TRAIN, etc.
    tool_name TEXT,
    input_summary TEXT,
    output_summary TEXT,
    agent_role TEXT,
    gate_result TEXT,  -- PASS/WARN/FAIL/NULL
    FOREIGN KEY (session_id) REFERENCES sessions(id)
);
CREATE INDEX idx_spine_session ON spine_entries(session_id, timestamp);
CREATE INDEX idx_spine_action ON spine_entries(action_type);

-- ═══════════════════════════════════════════════════════
-- CLAIMS: Full lifecycle tracking
-- ═══════════════════════════════════════════════════════

CREATE TABLE claim_events (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    claim_id TEXT NOT NULL,
    session_id TEXT NOT NULL,
    event_type TEXT NOT NULL,
    -- event_type: CREATED, PROMOTED, KILLED, DISPUTED, VERIFIED,
    --             R2_REVIEWED, GATE_PASSED, GATE_FAILED,
    --             CONFIDENCE_UPDATED, CONFOUNDER_TESTED
    old_status TEXT,
    new_status TEXT,
    confidence REAL,
    r2_verdict TEXT,  -- ACCEPT/REJECT/DEFER/NULL
    kill_reason TEXT,  -- INSUFFICIENT_EVIDENCE/CONFOUNDED/ARTIFACT/LOGICALLY_FALSE/NULL
    gate_id TEXT,
    narrative TEXT,  -- Descrizione umana dell'evento
    timestamp TEXT NOT NULL,
    FOREIGN KEY (session_id) REFERENCES sessions(id)
);
CREATE INDEX idx_claims_id ON claim_events(claim_id);
CREATE INDEX idx_claims_session ON claim_events(session_id);

-- ═══════════════════════════════════════════════════════
-- R2: Review quality tracking (per auto-calibration)
-- ═══════════════════════════════════════════════════════

CREATE TABLE r2_reviews (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    review_id TEXT NOT NULL UNIQUE,
    session_id TEXT NOT NULL,
    review_mode TEXT NOT NULL,  -- INLINE/FORCED/BATCH/SHADOW/BRAINSTORM
    claims_reviewed TEXT NOT NULL,  -- JSON array of claim_ids
    j0_score INTEGER,  -- R3 Judge total score (NULL if not FORCED)
    j0_dimensions TEXT,  -- JSON: {specificity: N, counter_evidence: N, ...}
    sfi_injected INTEGER DEFAULT 0,
    sfi_caught INTEGER DEFAULT 0,
    sfi_missed TEXT,  -- JSON array of missed fault IDs
    r2_weaknesses TEXT,  -- JSON array: cio' che R2 ha mancato (per calibration)
    timestamp TEXT NOT NULL,
    FOREIGN KEY (session_id) REFERENCES sessions(id)
);
CREATE INDEX idx_r2_session ON r2_reviews(session_id);

-- ═══════════════════════════════════════════════════════
-- SERENDIPITY: Seed survival across sessions
-- ═══════════════════════════════════════════════════════

CREATE TABLE serendipity_seeds (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    seed_id TEXT NOT NULL UNIQUE,
    created_session TEXT NOT NULL,
    status TEXT NOT NULL DEFAULT 'PENDING_TRIAGE',
    -- PENDING_TRIAGE, QUEUED, TESTING, KILLED, PROMOTED_TO_CLAIM
    source TEXT NOT NULL,  -- SCANNER/SALVAGED_FROM_R2/CROSS_BRANCH/USER
    score REAL,
    causal_question TEXT,
    discriminating_test TEXT,
    fallback_test TEXT,
    narrative TEXT,
    last_reviewed_session TEXT,
    resolution TEXT,
    created_at TEXT NOT NULL,
    updated_at TEXT NOT NULL,
    FOREIGN KEY (created_session) REFERENCES sessions(id)
);
CREATE INDEX idx_seeds_status ON serendipity_seeds(status);

-- ═══════════════════════════════════════════════════════
-- GATES: Enforcement tracking
-- ═══════════════════════════════════════════════════════

CREATE TABLE gate_checks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    gate_id TEXT NOT NULL,  -- DQ1, DQ2, DQ3, DQ4, DC0, DD0, L-1, G0-G6, etc.
    claim_id TEXT,
    status TEXT NOT NULL,  -- PASS/WARN/FAIL
    checks_passed INTEGER,
    checks_warned INTEGER,
    checks_failed INTEGER,
    details TEXT,  -- JSON con check specifici
    timestamp TEXT NOT NULL,
    FOREIGN KEY (session_id) REFERENCES sessions(id)
);
CREATE INDEX idx_gates_session ON gate_checks(session_id);
CREATE INDEX idx_gates_claim ON gate_checks(claim_id);

-- ═══════════════════════════════════════════════════════
-- LITERATURE: Search tracking per L-1+ enforcement
-- (Full definition in Section 10A.10)
-- ═══════════════════════════════════════════════════════

CREATE TABLE literature_searches (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    query TEXT NOT NULL,
    sources TEXT NOT NULL,
    results_count INTEGER,
    relevant_count INTEGER,
    key_papers TEXT,
    search_layer TEXT NOT NULL,
    gate_context TEXT,
    timestamp TEXT NOT NULL,
    FOREIGN KEY (session_id) REFERENCES sessions(id)
);
CREATE INDEX idx_lit_session ON literature_searches(session_id);
CREATE INDEX idx_lit_layer ON literature_searches(search_layer);

-- ═══════════════════════════════════════════════════════
-- OBSERVER: Alert tracking
-- ═══════════════════════════════════════════════════════

CREATE TABLE observer_alerts (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    project_path TEXT NOT NULL,
    level TEXT NOT NULL,  -- INFO/WARN/HALT
    message TEXT NOT NULL,
    resolved INTEGER DEFAULT 0,
    resolved_at TEXT,
    created_at TEXT NOT NULL
);
CREATE INDEX idx_observer_project ON observer_alerts(project_path, resolved);

-- ═══════════════════════════════════════════════════════
-- CALIBRATION: R5.5-01 (Confidence calibration log)
-- ═══════════════════════════════════════════════════════

CREATE TABLE calibration_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    claim_id TEXT NOT NULL,
    predicted_confidence REAL NOT NULL,
    actual_outcome TEXT NOT NULL,  -- VERIFIED/REJECTED/ARTIFACT/CONFOUNDED/ROBUST
    r2_verdict TEXT,
    stage_at_resolution INTEGER,
    session_id TEXT NOT NULL,
    timestamp TEXT NOT NULL,
    FOREIGN KEY (session_id) REFERENCES sessions(id)
);
CREATE INDEX idx_calibration_claim ON calibration_log(claim_id);

-- ═══════════════════════════════════════════════════════
-- PROMPT LOG: Audit trail
-- ═══════════════════════════════════════════════════════

CREATE TABLE prompt_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    agent_role TEXT,
    prompt_hash TEXT NOT NULL,  -- SHA-256, non il prompt intero (privacy)
    timestamp TEXT NOT NULL,
    FOREIGN KEY (session_id) REFERENCES sessions(id)
);
CREATE INDEX idx_prompt_session ON prompt_log(session_id);

-- ═══════════════════════════════════════════════════════
-- EMBEDDINGS: sqlite-vec virtual table
-- ═══════════════════════════════════════════════════════

CREATE VIRTUAL TABLE vec_memories USING vec0(
    embedding float[384],  -- all-MiniLM-L6-v2 dimension
    +text TEXT,
    +metadata TEXT,
    +project_path TEXT,
    +created_at TEXT
);

-- Queue per embedding async (processata dal worker)
CREATE TABLE embed_queue (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    text TEXT NOT NULL,
    metadata TEXT,
    created_at TEXT NOT NULL,
    processed INTEGER DEFAULT 0
);
CREATE INDEX idx_embed_pending ON embed_queue(processed) WHERE processed = 0;
```

### 5.2 Token Budget (Progressive Disclosure)

Il context injection a SessionStart segue la filosofia progressive disclosure di claude-mem, adattata:

```
Layer 1: STATE (~200 tokens)
├── Current stage, active claims, pending gates
├── Last action + next action (from STATE.md)
└── Session count, total claims, total gates

Layer 2: SEMANTIC CONTEXT (~500 tokens)
├── Top 3 relevant memories (via vec search on project context)
├── Unresolved observer alerts
└── R2 calibration hints

Total: ~700 tokens

vs. Loading everything: ~3000-5000 tokens
Savings: ~4x-7x
```

**Quando caricare di piu':** L'agent puo' sempre fare una ricerca esplicita nel DB via i MCP tools (se configurati) o leggendo direttamente i file in `.vibe-science/`. Il context injection e' il MINIMO necessario per non partire da zero.

### 5.3 Data Separation

```
~/.vibe-science/                    # GLOBALE (cross-progetto)
├── db/
│   └── vibe-science.db             # Database unico
├── logs/
│   └── worker-2026-02-20.log
├── embeddings/
│   └── model/                      # all-MiniLM-L6-v2 cached
└── settings.json                   # Configurazione globale

.vibe-science/                      # PROGETTO (per progetto, nel working dir)
├── STATE.md                        # Stato corrente (LAW 7: resumability)
├── PROGRESS.md                     # Log append-only
├── CLAIM-LEDGER.md                 # Claims + evidence
├── TREE-STATE.json                 # Albero serializzato
├── SERENDIPITY.md                  # Scoperte inaspettate
├── ASSUMPTION-REGISTER.md          # Assunzioni
├── SPINE.md                        # Research Spine (logbook auto)
├── schemas/                        # 12 JSON Schema (READ-ONLY)
├── protocols/                      # Copia dei protocolli attivi
└── RQ-xxx/                         # Sotto-directory per Research Question
    ├── 01-brainstorm/
    ├── 02-data/
    ├── 03-analysis/
    ├── 04-results/
    ├── 05-reviewer2/
    └── 07-eval/
```

**Invariante LAW 7:** Il sistema DEVE essere resumabile da `STATE.md + TREE-STATE.json` ANCHE senza il database SQLite. Il DB arricchisce il contesto (memorie, calibration, claim history) ma non e' indispensabile per il resume base. Fallback graceful.

---

## 6. Auto-Calibration Loop (Il Cuore di v6.0)

### 6.1 Il problema

v5.0-v5.5 sono statici: le regole non cambiano in base all'esperienza. R2 che manca sempre feature validation non viene mai avvisato. Un ricercatore che ripete lo stesso errore non viene mai allertato. I seed di serendipity muoiono tra le sessioni.

### 6.2 La soluzione: apprendere dall'esperienza

```
┌─────────────────────────────────────────────────────┐
│                AUTO-CALIBRATION LOOP                 │
│                                                       │
│   SessionStart                                        │
│      │                                                │
│      ▼                                                │
│   ┌──────────────────────────────────┐               │
│   │  LOAD CALIBRATION DATA           │               │
│   │  - R2 weakness history           │               │
│   │  - Researcher error patterns     │               │
│   │  - SFI catch rates by category   │               │
│   │  - Seed survival rates           │               │
│   └──────────────┬───────────────────┘               │
│                  │                                     │
│                  ▼                                     │
│   ┌──────────────────────────────────┐               │
│   │  INJECT INTO CONTEXT              │               │
│   │  - "R2: nelle ultime 5 sessioni  │               │
│   │    hai mancato feature validation │               │
│   │    3 volte. Fai attenzione."     │               │
│   │  - "Researcher: hai ripetuto      │               │
│   │    l'errore di non documentare   │               │
│   │    colonne in 2 sessioni."       │               │
│   │  - SFI: inject faults tipo X     │               │
│   │    (i tipi mancati recentemente) │               │
│   └──────────────┬───────────────────┘               │
│                  │                                     │
│                  ▼                                     │
│            [SESSIONE DI RICERCA]                      │
│                  │                                     │
│                  ▼                                     │
│   ┌──────────────────────────────────┐               │
│   │  STOP: RECORD OUTCOMES            │               │
│   │  - R2: cosa ha mancato/trovato   │               │
│   │  - Researcher: errori fatti       │               │
│   │  - SFI: catch rate questa sessione│               │
│   │  - Seeds: sopravvissuti/morti     │               │
│   └──────────────────────────────────┘               │
│                                                       │
└─────────────────────────────────────────────────────┘
```

### 6.3 R2 Auto-Calibration

```javascript
// plugin/lib/r2-calibration.js

function loadR2CalibrationData(db, projectPath) {
    // Ultimi 10 review con weaknesses
    const recentReviews = db.all(`
        SELECT review_mode, r2_weaknesses, sfi_caught, sfi_injected, j0_score
        FROM r2_reviews
        WHERE session_id IN (
            SELECT id FROM sessions WHERE project_path = ?
            ORDER BY started_at DESC LIMIT 10
        )
        ORDER BY timestamp DESC LIMIT 20
    `, projectPath);

    // Analizza pattern di debolezza
    const weaknessPatterns = {};
    for (const review of recentReviews) {
        if (review.r2_weaknesses) {
            const weaknesses = JSON.parse(review.r2_weaknesses);
            for (const w of weaknesses) {
                weaknessPatterns[w] = (weaknessPatterns[w] || 0) + 1;
            }
        }
    }

    // SFI catch rate per categoria
    const sfiStats = db.all(`
        SELECT
            json_each.value as fault_type,
            COUNT(*) as missed_count
        FROM r2_reviews, json_each(r2_reviews.sfi_missed)
        WHERE sfi_missed IS NOT NULL
        GROUP BY json_each.value
        ORDER BY missed_count DESC
    `);

    // J0 score trend
    const j0Scores = recentReviews
        .filter(r => r.j0_score !== null)
        .map(r => r.j0_score);
    const j0Trend = j0Scores.length >= 3
        ? (j0Scores.slice(0, 3).reduce((a, b) => a + b, 0) / 3 >
           j0Scores.slice(-3).reduce((a, b) => a + b, 0) / 3 ? 'declining' : 'improving')
        : 'insufficient_data';

    return {
        topWeaknesses: Object.entries(weaknessPatterns)
            .sort((a, b) => b[1] - a[1])
            .slice(0, 3),
        sfiWeakCategories: sfiStats.slice(0, 3),
        j0Trend,
        totalReviews: recentReviews.length,
        hint: generateR2Hint(weaknessPatterns, sfiStats, j0Trend)
    };
}

function generateR2Hint(weaknesses, sfiStats, j0Trend) {
    const hints = [];

    // Weakness-based hints
    const topW = Object.entries(weaknesses).sort((a, b) => b[1] - a[1])[0];
    if (topW && topW[1] >= 2) {
        hints.push(`R2 ha storicamente mancato "${topW[0]}" ${topW[1]} volte. Priorita' alta.`);
    }

    // SFI-based hints
    if (sfiStats.length > 0) {
        hints.push(`SFI: R2 manca piu' spesso fault tipo "${sfiStats[0].fault_type}". ` +
                   `Iniettare faults di questa categoria con priorita'.`);
    }

    // J0 trend
    if (j0Trend === 'declining') {
        hints.push(`J0 score in calo nelle ultime sessioni. R2 review quality sta degradando.`);
    }

    return hints.join(' ');
}
```

**Come viene usato:** Il hint viene iniettato nel context a SessionStart. L'agent R2 riceve informazioni sulle sue debolezze storiche PRIMA di iniziare la review. L'orchestrator usa le sfiWeakCategories per scegliere i fault da iniettare con SFI. Questo crea un loop di miglioramento continuo.

### 6.4 Researcher Pattern Recognition

```javascript
function loadResearcherPatterns(db, projectPath) {
    // Errori ripetuti
    const errors = db.all(`
        SELECT action_type, input_summary, COUNT(*) as occurrences
        FROM spine_entries
        WHERE session_id IN (
            SELECT id FROM sessions WHERE project_path = ?
        )
        AND action_type = 'BUG_FIX'
        GROUP BY input_summary
        HAVING occurrences >= 2
        ORDER BY occurrences DESC
        LIMIT 5
    `, projectPath);

    // Gate failure patterns
    const gateFailures = db.all(`
        SELECT gate_id, COUNT(*) as fail_count
        FROM gate_checks
        WHERE session_id IN (
            SELECT id FROM sessions WHERE project_path = ?
        )
        AND status = 'FAIL'
        GROUP BY gate_id
        ORDER BY fail_count DESC
        LIMIT 5
    `, projectPath);

    return {
        repeatedErrors: errors,
        gateWeakpoints: gateFailures,
        hint: errors.length > 0
            ? `Attenzione: errore "${errors[0].input_summary}" ripetuto ${errors[0].occurrences} volte.`
            : null
    };
}
```

### 6.5 Seed Survival Across Sessions

In v5.5, i semi di serendipita' vivono in `SERENDIPITY.md` e muoiono quando la sessione finisce (dimenticati). In v6.0:

```javascript
// Al SessionStart: carica semi pendenti
function loadPendingSeeds(db, projectPath) {
    return db.all(`
        SELECT seed_id, causal_question, discriminating_test, score, created_at
        FROM serendipity_seeds
        WHERE status IN ('PENDING_TRIAGE', 'QUEUED')
        AND created_session IN (
            SELECT id FROM sessions WHERE project_path = ?
        )
        ORDER BY score DESC
        LIMIT 5
    `, projectPath);
}

// Al Stop: aggiorna stato semi
function updateSeedStatus(db, sessionId, seedUpdates) {
    for (const update of seedUpdates) {
        db.run(`UPDATE serendipity_seeds
                SET status = ?, last_reviewed_session = ?, updated_at = ?
                WHERE seed_id = ?`,
            update.status, sessionId, new Date().toISOString(), update.seed_id
        );
    }
}
```

**Regola LAW 5 rafforzata:** Un seme con status PENDING_TRIAGE da piu' di 5 sessioni (non 5 cicli — ora cross-sessione) viene ESCALATED. Il context injection lo evidenzia con priorita' alta.

---

## 7. TEAM Mode: Permission Enforcement

### 7.1 Come funziona

Claude Code con Agent Teams (`CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS=1`) lancia sotto-agent con ruoli. Il plugin identifica il ruolo e applica permessi.

```javascript
// plugin/lib/permission-engine.js

function identifyAgentRole(agentInfo, prompt) {
    // Claude Code passa informazioni sull'agent nel contesto
    // In Team mode: il lead assegna ruoli espliciti
    // In Solo mode: inferisci dal contenuto

    if (agentInfo?.role) return agentInfo.role;

    // Fallback: inferisci dal contenuto del prompt
    const lowerPrompt = prompt.toLowerCase();
    if (lowerPrompt.includes('reviewer') || lowerPrompt.includes('r2'))
        return 'reviewer2';
    if (lowerPrompt.includes('serendipity') || lowerPrompt.includes('scanner'))
        return 'serendipity';
    if (lowerPrompt.includes('judge') || lowerPrompt.includes('r3'))
        return 'judge';
    if (lowerPrompt.includes('experiment'))
        return 'experimenter';

    return 'researcher';  // Default
}

function checkPermission(role, toolName, toolInput) {
    const perms = PERMISSIONS[role];
    if (!perms) return null;  // Unknown role → allow (fail open for safety)

    // Check tool allowed
    if (!perms.allow.includes(toolName)) {
        return {
            action: `use tool ${toolName}`,
            reason: `Tool ${toolName} not in allowed list for ${role}`,
            required_role: 'researcher or lead'
        };
    }

    // Check file write restrictions
    if ((toolName === 'Write' || toolName === 'Edit') && toolInput.file_path) {
        const filePath = toolInput.file_path;

        // Deny specific files
        for (const denied of (perms.deny_files || [])) {
            if (filePath.includes(denied)) {
                return {
                    action: `write to ${denied}`,
                    reason: `Agent ${role} cannot write to ${denied}`,
                    required_role: 'researcher (for CLAIM-LEDGER), orchestrator (for execution)'
                };
            }
        }

        // Deny patterns
        for (const pattern of (perms.deny_patterns || [])) {
            if (minimatch(filePath, pattern)) {
                return {
                    action: `write to ${filePath}`,
                    reason: `Pattern ${pattern} denied for ${role}`,
                    required_role: 'owner of that directory'
                };
            }
        }

        // Allow-write-only: if defined, can ONLY write to those dirs
        if (perms.allow_write_only && perms.allow_write_only.length > 0) {
            const allowed = perms.allow_write_only.some(dir => filePath.includes(dir));
            if (!allowed) {
                return {
                    action: `write to ${filePath}`,
                    reason: `Agent ${role} can only write to: ${perms.allow_write_only.join(', ')}`,
                    required_role: 'researcher or lead'
                };
            }
        }
    }

    return null;  // Permitted
}
```

### 7.2 Scenari concreti

| Scenario | Agent | Azione | Risultato |
|----------|-------|--------|-----------|
| R2 tenta di scrivere CLAIM-LEDGER | reviewer2 | Edit CLAIM-LEDGER.md | **BLOCKED** (exit 2): "R2 cannot write to CLAIM-LEDGER. Produce a verdict artifact." |
| R2 scrive il suo report | reviewer2 | Write 05-reviewer2/report.yaml | **ALLOWED** |
| Judge tenta di modificare report R2 | judge | Edit 05-reviewer2/report.yaml | **BLOCKED**: "Judge cannot write to R2 reports" |
| Researcher scrive FINDINGS.md | researcher | Write FINDINGS.md | **ALLOWED** (ma DQ4 sync check potrebbe bloccare) |
| Serendipity scrive nel ledger | serendipity | Edit CLAIM-LEDGER.md | **BLOCKED**: "Serendipity can only write to SERENDIPITY.md" |

### 7.3 Separation of Powers (da v5.0, ora enforced)

v5.0 definiva questa matrice come convenzione. v6.0 la enforce via codice:

| Agent | Claim Ledger | R2 Reports | Schemas | Gate Artifacts |
|-------|-------------|------------|---------|---------------|
| Researcher | READ+WRITE | READ | READ | READ+WRITE |
| R2 Ensemble | **READ only (ENFORCED)** | WRITE | READ | READ only |
| R3 Judge | READ only | **READ only (ENFORCED)** | READ | READ only |
| Serendipity | READ only | READ only | READ | READ only |
| Lead | READ+WRITE | READ | READ | READ |
| Orchestrator | READ+WRITE | READ | READ (enforce) | READ+VALIDATE |

---

## 8. Installazione e Setup

### 8.1 Zero-Friction Install

```
# 3 comandi, come claude-mem
/plugin marketplace add vibe-science/vibe-science
/plugin install vibe-science
# Restart Claude Code
```

### 8.2 Cosa fa il Setup Hook

```
setup.js execution:
  1. [Check Node.js version >= 18.0.0]                 ✓ (prerequisito Claude Code)
  2. [Detect Bun vs npm]                                Bun se presente, fallback npm
  3. [Create ~/.vibe-science/ directories]              db/, logs/
  4. [Initialize SQLite database from schema.sql]       ~/.vibe-science/db/vibe-science.db
  5. [Check/install dependencies]                       Smart marker: .install-marker
     - Se .install-marker esiste e ha < 24h → skip
     - Altrimenti: run `{bun|npm} install` + aggiorna marker
  6. [Launch worker daemon]                             PID file: .worker.pid
     - Controlla se worker gia' attivo (PID file)
     - Se non attivo: spawn worker-embed.js come daemon
  7. [Return JSON status object]                        { status, db_path, worker_pid,
                                                          deps_installed, node_version,
                                                          model_status }

Tempo totale prima installazione: ~15 secondi (modello ~23 MB quantized ONNX, lazy download)
Tempo su avvii successivi: <1 secondo (marker check + PID check)
```

### 8.3 Dipendenze

| Dipendenza | Dimensione | Installazione | Perche' |
|-----------|-----------|---------------|---------|
| **Node.js >= 18.0.0** | 0 (prerequisito Claude Code) | Gia' presente | Runtime principale |
| **better-sqlite3** | ~2 MB | npm install | Binding SQLite nativo per Node.js |
| **sqlite-vec** | ~1 MB | Bundled nel plugin | Ricerca vettoriale in SQLite |
| **@huggingface/transformers ^3.4.0** | ~5 MB (libreria) | npm install | ML model loading and inference (lazy) |
| **onnxruntime-node ^1.21.0** | ~15 MB | npm install | ONNX runtime for Node.js |
| **Xenova/all-MiniLM-L6-v2** | ~23 MB (quantized ONNX) | Download lazy al primo embedding | Embedding per ricerca semantica |
| **Bun** (opzionale) | ~30 MB | Rilevato automaticamente | Se presente, usato come package manager al posto di npm |

**Totale: ~46 MB** (vs ~120 MB nel design originale, vs ~200 MB per Chroma + sentence-transformers di v5.5)

**Nessuna dipendenza Python.** Tutto il sistema gira su Node.js. Bun e' opzionale (rilevato con fallback a npm). Il modello e' ~23 MB (quantized ONNX) invece dei ~90 MB originariamente stimati.

---

## 9. Progressive Disclosure

### 9.1 Il pattern (da claude-mem, adattato)

claude-mem usa 3 layer: `search` (indice, ~50-100 tokens/result) → `timeline` (contesto cronologico) → `get_observations` (dettagli completi, ~500-1000 tokens/result). Token savings: ~10x.

v6.0 adatta questo pattern al contesto scientifico:

```
Layer 1: STATE SNAPSHOT (~200 tokens)
  Automatico a SessionStart.
  Contenuto:
  - Stage corrente, claim attive, gate pendenti
  - Ultima azione + prossima azione
  - Contatore sessioni, claims totali

Layer 2: SEMANTIC RECALL (~500 tokens)
  Automatico a UserPromptSubmit.
  Contenuto:
  - Top 3 memorie rilevanti (via sqlite-vec)
  - Alert Observer non risolti
  - R2 calibration hint
  - Semi di serendipita' pendenti

Layer 3: FULL DETAIL (on demand)
  Su richiesta esplicita dell'agent.
  Contenuto:
  - Narrativa completa della sessione precedente
  - Tutti i claim_events per un claim specifico
  - Report R2 completi
  - Gate check completi con dettagli

Token totale Layer 1+2: ~700 tokens
Token totale se si carica tutto: ~3000-5000 tokens
Savings: 4x-7x
```

### 9.2 Implementazione

```javascript
// plugin/lib/context-builder.js

function buildContext(db, projectPath, sessionId) {
    const context = {};

    // Layer 1: State snapshot
    const lastSession = db.get(`
        SELECT narrative_summary, total_actions, claims_created, claims_killed
        FROM sessions
        WHERE project_path = ?
        ORDER BY ended_at DESC LIMIT 1
    `, projectPath);

    context.state = lastSession
        ? `Ultima sessione: ${lastSession.total_actions} azioni, ` +
          `${lastSession.claims_created} claims create, ${lastSession.claims_killed} killed.\n` +
          `Summary: ${truncate(lastSession.narrative_summary, 200)}`
        : 'Prima sessione su questo progetto.';

    // Layer 2: Semantic recall (top 3 relevant memories)
    // Query = project name + recent actions
    const queryText = `${path.basename(projectPath)} research context`;
    context.memories = vecSearch(db, queryText, {
        project_path: projectPath,
        limit: 3,
        maxTokens: 500
    });

    // Layer 2: R2 calibration
    context.r2Calibration = loadR2CalibrationData(db, projectPath);

    // Layer 2: Pending seeds
    context.pendingSeeds = loadPendingSeeds(db, projectPath);

    // Layer 2: Observer alerts
    context.alerts = db.all(`
        SELECT level, message FROM observer_alerts
        WHERE project_path = ? AND resolved = 0
        ORDER BY level DESC LIMIT 5
    `, projectPath);

    return context;
}

function formatContextForInjection(context, alerts, r2Stats) {
    const parts = [];

    parts.push('--- VIBE SCIENCE CONTEXT ---');

    // State
    parts.push(`[STATE] ${context.state}`);

    // Memories
    if (context.memories.length > 0) {
        parts.push('[MEMORY]');
        for (const m of context.memories) {
            parts.push(`  - ${truncate(m.text, 150)}`);
        }
    }

    // Alerts
    if (context.alerts.length > 0) {
        parts.push('[ALERTS]');
        for (const a of context.alerts) {
            parts.push(`  - [${a.level}] ${a.message}`);
        }
    }

    // R2 calibration
    if (r2Stats.hint) {
        parts.push(`[R2 CALIBRATION] ${r2Stats.hint}`);
    }

    // Pending seeds
    if (context.pendingSeeds.length > 0) {
        parts.push('[PENDING SEEDS]');
        for (const s of context.pendingSeeds) {
            parts.push(`  - ${s.seed_id}: ${truncate(s.causal_question, 100)} (score: ${s.score})`);
        }
    }

    parts.push('--- END CONTEXT ---');

    return parts.join('\n');
}
```

---

## 10. Domain-Specific Skills e Blueprints

### 10.1 Il principio

L'infrastruttura (plugin) e' **domain-agnostic**: funziona per CRISPR, fotonica, o qualsiasi altro dominio.
La metodologia (skill) e' **domain-agnostic**: OTAE, R2, gates funzionano per qualsiasi ricerca.
I **blueprint** sono **domain-specific**: contengono le configurazioni, le soglie, e le conoscenze esperte per un dominio specifico.

```
vibe-science-v6.0/
├── plugin/          ← Domain-agnostic (uguale per tutti)
├── skill/           ← Domain-agnostic (uguale per tutti)
└── blueprints/      ← Domain-specific (diverso per dominio)
    ├── v5.0-IUDEX-BLUEPRINT.md          # Architettura base
    ├── v5.5-ORO-BLUEPRINT.md            # Post-mortem CRISPR
    ├── v6.0-NEXUS-BLUEPRINT.md          # Questo documento
    └── PHOTONICS-BLUEPRINT.md           # Fork fotonica
```

### 10.2 Come i blueprint vengono usati

I blueprint NON sono caricati automaticamente nel context (troppi token). Vengono consultati:

1. **A SessionStart:** Il plugin controlla se esiste un blueprint per il dominio corrente (basandosi su pattern nel project path o su una configurazione in `settings.json`). Se si', aggiunge al context una riga: `[BLUEPRINT] Domain: CRISPR. Reference: blueprints/v5.5-ORO-BLUEPRINT.md. Load on demand.`

2. **Su richiesta:** Quando l'agent ha bisogno di soglie specifiche (es. DQ1 thresholds per CRISPR), legge il blueprint.

3. **Per gate configurabili:** Le soglie dei DQ gates (mean_mismatch [2,8], R² > 0.05, etc.) sono specifiche per dominio. Il blueprint le definisce. Il plugin le legge da un file di configurazione domain-specific:

```json
// .vibe-science/domain-config.json (creato dal blueprint)
{
    "domain": "crispr-off-target",
    "literature": {
        "primary": ["pubmed", "biorxiv", "pmc"],
        "secondary": ["openalex", "semantic_scholar", "crossref"],
        "datasets": ["geo", "sra", "ena"],
        "preprints": ["biorxiv", "medrxiv"],
        "grey": [],
        "curated_rag": null
    },
    "dq1": {
        "mean_mismatch_range": [2, 8],
        "cfd_nonzero_threshold": 0.30,
        "leakage_corr_threshold": 0.95
    },
    "dq2": {
        "min_auc": 0.55,
        "min_r2": 0.05,
        "max_dominance": 0.50,
        "max_fold_cv": 0.50
    },
    "dq3": {
        "max_coverage_gap": 0.10,
        "max_coverage": 0.999
    }
}
```

Per la fotonica, queste soglie sarebbero diverse (es. SNR thresholds, wavelength ranges). Il plugin legge il config; la skill e i gate restano invariati.

### 10.3 Fork domain-specific

Il Photonics fork (ORO-PHOTONICS) mantiene la sua indipendenza:

```
vibe-science-photonics/             # Fork esistente (skill only)
├── SKILL.md                        # v5.5 ORO-PHOTONICS (con R2-Physics, HE0-HE3)
├── CLAUDE.md                       # Constitution con regole fisiche
├── protocols/                      # 29 + protocolli photonics-specific
├── gates/                          # 36 gate (34 base + HE0-HE3 - overlap)
└── ...
```

In v6.0, il fork puo':
1. Usare lo stesso plugin (infrastruttura identica)
2. Avere la propria `skill/` directory con SKILL.md modificato per fotonica
3. Avere il proprio domain-config.json con soglie fotoniche

La struttura diventa:

```
vibe-science-v6.0/
├── plugin/                          # Condiviso
├── skill/                           # Base (CRISPR/general)
├── skill-photonics/                 # Override fotonica (opzionale)
│   ├── SKILL.md                     # Override con R2-Physics, HE0-HE3
│   └── protocols/                   # Protocolli aggiuntivi
└── blueprints/
```

---

## 10A. Literature Engine: Cross-Domain Discovery

### 10A.1 Il problema

Gate L-1 (Literature Pre-Check) in v5.5 era prompt-level e implicitamente biased verso la biomedicina: i default erano PubMed + bioRxiv. Per un ricercatore in fotonica, fisica delle particelle, chimica dei materiali, o scienze sociali, queste fonti sono irrilevanti o incomplete.

Tre problemi concreti:
1. **Domain bias**: un agent senza guida cerca su PubMed anche per problemi di ottica integrata
2. **Fonti ignote**: esistono 100+ database scientifici — nessun agent li conosce tutti
3. **Stack frammentato**: MCP servers, scientific skills, RAG locali sono strumenti complementari ma non integrati

### 10A.2 Architettura a 4 livelli

```
┌─────────────────────────────────────────────────┐
│ Layer 3: Local RAG (letteratura curata)          │
│   NotebookLM / PaperQA2 / Zotero MCP            │
├─────────────────────────────────────────────────┤
│ Layer 2: Scientific Skills (K-Dense-AI)          │
│   28+ database skills + literature-review        │
│   + research-lookup + citation-management        │
├─────────────────────────────────────────────────┤
│ Layer 1: MCP Server Stack (API access)           │
│   Scientific-Papers-MCP / paper-search-mcp       │
│   nasa-ads-mcp / mcp.science / arxiv-mcp        │
├─────────────────────────────────────────────────┤
│ Layer 0: Domain Registry                         │
│   literature-registry.json + domain-config.json  │
└─────────────────────────────────────────────────┘
```

Ogni layer e' **indipendente e opzionale**. Si puo' usare solo L0+L2 (skills, no MCP), o L0+L1 (MCP, no skills), o tutti e 4. Il plugin seleziona il percorso basandosi su domain-config.json.

**Principio chiave:** il Literature Engine NON sostituisce la capacita' dell'agent di scaricare dataset, scrivere script Python, e analizzare dati grezzi. Quella capacita' (usata nel lavoro CRISPR per GUIDE-seq, CHANGE-seq, etc.) resta intatta. Il Literature Engine la COMPLEMENTA fornendo contesto e prior art.

### 10A.3 Layer 0: Domain Registry

Due file configurano il Literature Engine:

**`literature-registry.json`** — catalogo master di 105+ database, machine-readable:

```json
{
  "databases": {
    "pubmed": {
      "name": "PubMed/MEDLINE",
      "category": ["biomedical", "life_sciences"],
      "access": "free",
      "api": true,
      "api_type": "REST",
      "mcp_server": "openags/paper-search-mcp",
      "kdense_skill": "pubmed-database",
      "coverage": "36M+ citations"
    },
    "optica": {
      "name": "Optica Publishing (ex-OSA)",
      "category": ["photonics", "optics"],
      "access": "mixed",
      "api": true,
      "api_type": "REST",
      "mcp_server": null,
      "kdense_skill": null,
      "coverage": "Optics Letters, JOSA, Applied Optics"
    }
  }
}
```

**`domain-config.json`** — esteso con sezione `literature`:

```json
{
  "domain": "crispr-off-target",
  "literature": {
    "primary": ["pubmed", "biorxiv", "pmc"],
    "secondary": ["openalex", "semantic_scholar", "crossref"],
    "datasets": ["geo", "sra", "ena"],
    "preprints": ["biorxiv", "medrxiv"],
    "grey": [],
    "curated_rag": null
  },
  "dq1": { "...": "..." }
}
```

Per la fotonica:

```json
{
  "domain": "photonics-integrated",
  "literature": {
    "primary": ["optica", "spie", "ieee_xplore"],
    "secondary": ["openalex", "semantic_scholar", "arxiv"],
    "datasets": ["materials_project", "nist_asd"],
    "preprints": ["arxiv"],
    "grey": [],
    "curated_rag": "notebooklm"
  }
}
```

Per la fisica delle particelle:

```json
{
  "domain": "particle-physics",
  "literature": {
    "primary": ["inspire_hep", "arxiv", "cern_cds"],
    "secondary": ["nasa_ads", "openalex"],
    "datasets": ["pdg"],
    "preprints": ["arxiv"],
    "grey": [],
    "curated_rag": null
  }
}
```

### 10A.4 Tassonomia dei Database Scientifici (105+ fonti)

La tabella seguente cataloga le principali fonti per dominio. La versione completa machine-readable e' in `literature-registry.json`.

**Legenda:** MCP = MCP server disponibile | SK = K-Dense-AI skill disponibile | F = Free | S = Abbonamento | M = Misto/Freemium

#### Multidisciplinari / Aggregatori

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| Google Scholar | Cross-disciplinary | F | — | — |
| Scopus | 90M+ records, peer-reviewed | S | — | — |
| Web of Science | 170M+ records, citation index | S | — | — |
| OpenAlex | 240M+ works, open citations | F | si | si |
| Semantic Scholar | 200M+ papers, AI-driven | F | si | — |
| Dimensions | 130M+ publications | M | — | — |
| CORE | 200M+ full-text OA | F | si | — |
| BASE | 300M+ documenti (OAI-PMH) | F | — | — |
| Crossref | 140M+ DOI metadata | F | — | — |
| Lens.org | Patents + scholarly | F | — | — |
| Unpaywall | OA finder via DOI | F | — | — |

#### Biologia / Life Sciences

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| PubMed/MEDLINE | 36M+ biomedical citations | F | si | si |
| bioRxiv | Preprint biology | F | si | si |
| medRxiv | Preprint medicine | F | si | — |
| Europe PMC | 40M+ life sciences | F | si | — |
| PubMed Central | Full-text OA biomedical | F | si | — |
| GEO | Gene expression datasets | F | — | si |
| SRA | Sequencing reads archive | F | — | — |
| ENA | European Nucleotide Archive | F | — | si |
| UniProt | Protein sequences/function | F | — | si |
| Ensembl | Genome annotations (200+ species) | F | — | si |
| NCBI Gene | Gene records | F | — | si |
| ClinVar | Clinical variant significance | F | — | si |
| COSMIC | Cancer somatic mutations | M | — | si |
| KEGG | Pathways, metabolic networks | F* | — | si |
| Reactome | Pathway analysis (human focus) | F | — | si |
| STRING | Protein-protein interactions | F | — | si |
| AlphaFold DB | 200M+ predicted protein structures | F | — | si |
| PDB/RCSB | 3D macromolecular structures | F | — | si |
| GWAS Catalog | SNP-trait associations | F | — | si |
| Open Targets | Target-disease associations | F | — | si |
| ClinicalTrials.gov | Clinical studies registry | F | — | si |
| Dryad | Research datasets (life sciences) | F | — | — |
| Figshare | Dati, figure, preprint | F | — | — |
| FlowRepository | Flow cytometry data | F | — | — |

#### Chimica / Farmacologia

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| PubChem | 111M+ compounds | F | — | si |
| ChEMBL | Bioactive molecules, drug discovery | F | — | si |
| DrugBank | Comprehensive drug data | M | — | si |
| ZINC | 230M+ purchasable compounds | F | — | si |
| ChemSpider | 100M+ structures (RSC) | F | — | — |
| SciFinder/CAS | Chemical abstracts | S | — | — |
| Reaxys | Reaction database | S | — | — |
| BRENDA | Enzyme kinetics data | F | — | si |
| HMDB | 220K+ human metabolites | F | — | si |
| Metabolomics Workbench | NIH metabolomics | F | — | si |

#### Fisica / Matematica / Astronomia

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| arXiv | Preprint phys/CS/math/bio | F | si | — |
| INSPIRE-HEP | High-energy physics | F | — | — |
| NASA ADS | Astronomy/astrophysics | F | si | — |
| MathSciNet | Mathematics reviews (AMS) | S | — | — |
| zbMATH | Mathematics | M | — | — |
| CERN CDS | CERN documents | F | — | — |
| PDG | Particle data reviews | F | — | — |
| NIST Atomic Spectra | Spettri atomici, dati ottici | F | — | — |
| SLAC SPIRES (ora INSPIRE) | HEP literature (storico) | F | — | — |

#### Materiali / Fotonica / Ingegneria

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| Materials Project | Crystal structures calc. (DFT) | F | si | si |
| ICSD | Inorganic crystal structures | S | — | — |
| CSD | Cambridge structural database | S | — | — |
| Springer Materials | Proprietà materiali (Landolt-Börnstein) | S | — | — |
| IEEE Xplore | Engineering, EE, photonics | S | — | — |
| SPIE Digital Library | Imaging, optics, remote sensing | S | — | — |
| Optica Publishing | Optics Letters, JOSA, Applied Optics | M | — | — |
| Engineering Village | Compendex | S | — | — |

#### Informatica / AI

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| DBLP | CS bibliographic (conferences/journals) | F | — | — |
| ACM Digital Library | Computing full-text | S | — | — |
| ACL Anthology | Computational linguistics | F | si | — |
| Papers With Code | ML papers + code + benchmarks | F | — | — |
| NeurIPS/ICML archives | ML conference proceedings | F | — | — |
| ERIC | Education + CS education | F | — | — |

#### Medicina / Clinical

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| Cochrane Library | Systematic reviews (gold standard) | S | — | — |
| CINAHL | Nursing, allied health | S | — | — |
| Embase | Pharmacology, biomedicine | S | — | — |
| ClinPGx | Pharmacogenomics | F | — | si |
| openFDA | FDA drug/device/adverse events | F | — | si |

#### Scienze Sociali / Umanistiche

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| JSTOR | Humanities/SS archive | S | — | — |
| SSRN | Social science preprints | F | — | — |
| EconLit | Economics | S | — | — |
| PsycINFO | Psychology | S | — | — |
| PhilPapers | Philosophy | F | — | — |
| HathiTrust | Digitized books | F | — | — |
| Project MUSE | Humanities journals | S | — | — |

#### Scienze della Terra / Ambiente

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| GeoRef | Geosciences | S | — | — |
| Pangaea | Earth system data archive | F | — | — |
| GBIF | Biodiversity occurrences | F | — | — |
| NASA Earthdata | Satellite, climate data | F | — | — |

#### Preprint (domain-specific)

| Database | Dominio | Acc. | MCP | SK |
|---|---|---|---|---|
| ChemRxiv | Chemistry | F | — | — |
| EarthArXiv | Earth science | F | — | — |
| ESSOAr | Earth/space science | F | — | — |
| engrXiv | Engineering | F | — | — |

#### Regionali

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| CNKI | Letteratura cinese | S | — | — |
| J-STAGE | Letteratura giapponese | F | — | — |
| SciELO | America Latina, OA | F | — | — |
| AJOL | Africa journals | F | — | — |
| KCI | Korea | F | — | — |
| Redalyc | Riviste latinoamericane OA | F | — | — |

#### Grey Literature / Speciali

| Database | Copertura | Acc. | MCP | SK |
|---|---|---|---|---|
| OpenGrey | Report tecnici, tesi UE | F | — | — |
| GreyLit | Grey literature USA | F | — | — |
| World Bank OKR | Sviluppo, economia | F | — | — |
| USPTO | Patents, trademarks | F | — | si |
| Google Patents | Multi-office patent search | F | — | — |
| Espacenet | EPO patent search | F | — | — |
| PASCAL/FRANCIS | Archivio scienze/humanities (fino 2015) | F | — | — |
| SciVal | Analytics istituzionali (Elsevier) | S | — | — |

**Totale: 105+ database catalogati in 12 categorie.**

### 10A.5 Layer 1: MCP Server Stack

Server MCP esistenti e testati per la letteratura scientifica (febbraio 2026):

| Server | Coverage | Tools principali |
|---|---|---|
| `benedict2310/Scientific-Papers-MCP` | arXiv, OpenAlex, PMC, Europe PMC, bioRxiv, CORE | search, fetch, citations |
| `openags/paper-search-mcp` | arXiv, PubMed, bioRxiv, medRxiv, Google Scholar, Semantic Scholar | multi-source search |
| `blazickjp/arxiv-mcp-server` | arXiv | search, fetch, summarize |
| `prtc/nasa-ads-mcp` | NASA ADS (astronomy/astrophysics) | search, citations |
| `IlyaGusev/academia_mcp` | arXiv, ACL Anthology, HuggingFace, Semantic Scholar | search, fetch |
| `pathintegral-institute/mcp.science` | Materials Project, GPAW, NEMAD | materials/physics queries |

**Configurazione in Claude Code `settings.json`:**

```json
{
  "mcpServers": {
    "scientific-papers": {
      "command": "npx",
      "args": ["-y", "@benedict2310/scientific-papers-mcp"]
    },
    "paper-search": {
      "command": "npx",
      "args": ["-y", "@openags/paper-search-mcp"]
    }
  }
}
```

Il plugin NON gestisce i server MCP — sono configurati dall'utente in Claude Code settings. Il plugin li usa se disponibili, fallback su skills se non lo sono.

### 10A.6 Layer 2: Scientific Skills (K-Dense-AI)

K-Dense-AI fornisce 28+ database skills gia' disponibili (vedi colonna "SK" nelle tabelle sopra), piu' meta-skills critiche:

| Skill | Funzione |
|---|---|
| `literature-review` | Workflow PRISMA completo: search strategy, screening, extraction, synthesis |
| `research-lookup` | Dispatcher via Perplexity: dato un topic, cerca across multiple sources |
| `citation-management` | Gestione citazioni, formattazione, de-duplicazione |
| `peer-review` | Review strutturata con checklist |
| `scientific-brainstorming` | Ideazione creativa con vincoli disciplinari |
| `scholar-evaluation` | Valutazione qualita' delle fonti |

**Come si integra con il plugin:**

Le skills sono invocate dall'agent come parte del workflow OTAE. Il plugin non le chiama direttamente — sono prompt-level. Il plugin puo':
1. Verificare nel PostToolUse che una literature search sia stata fatta (L-1+ gate)
2. Loggare le fonti consultate nella tabella `literature_searches` del DB
3. Fornire nel context (SessionStart) le fonti raccomandate per il dominio corrente
4. Suggerire skills specifiche quando il dominio ha una skill K-Dense disponibile

### 10A.7 Layer 3: Local RAG (letteratura curata)

Per accompagnare la ricerca con letteratura selezionata dall'utente:

| Soluzione | Tipo | MCP Disponibile | Note |
|---|---|---|---|
| **Zotero** | Libreria personale | 5+ server MCP stabili | Best option per collezioni esistenti. API matura. |
| **PaperQA2** (Future House) | Scientific RAG | Non ancora MCP-wrapped | Best-in-class per retrieval + synthesis. Python CLI. |
| **NotebookLM** (Google) | Curated notebooks | Wrapper non ufficiali (browser automation) | Instabile per automazione; ottimo per uso manuale affiancato. |

**Configurazione in `domain-config.json`:**

```json
{
  "literature": {
    "curated_rag": "zotero",
    "rag_config": {
      "zotero_library": "group/12345",
      "collection": "CRISPR-safety"
    }
  }
}
```

**Raccomandazione:** Zotero MCP per progetti con letteratura curata. PaperQA2 via Bash per query una tantum. NotebookLM per uso manuale parallelo alla sessione.

### 10A.8 Gate L-1+ (potenziato da prompt a enforcement)

In v5.5, L-1 era un'istruzione nel prompt: "prima di definire la research direction, cerca la letteratura." Nessun enforcement — l'agent poteva ignorarlo.

In v6.0, L-1 diventa **L-1+** con enforcement a due punti:

**Punto 1: Pre-direction (BLOCKING)**

Prima che il Researcher possa scrivere un nodo direction nell'albero OTAE, il PostToolUse hook verifica che almeno una literature search sia stata registrata per questa sessione:

```javascript
// In post-tool-use.js, gate enforcement section
if (isDirectionNode(tool_input) && !hasLiteratureSearch(session_id, db)) {
    const domainConfig = loadDomainConfig();
    return {
        exitCode: 2,
        stderr: 'GATE L-1+ FAIL: Nessuna literature search registrata. ' +
                'Esegui una ricerca bibliografica prima di definire la direction.\n' +
                'Fonti consigliate per dominio "' + domainConfig.domain + '": ' +
                domainConfig.literature.primary.join(', ')
    };
}
```

**Punto 2: Durante OTAE (NON-BLOCKING, OBSERVER)**

Ad ogni ciclo OTAE, il plugin logga se una literature search e' stata fatta. Se dopo 3 cicli consecutivi senza literature search, emette un WARNING nel context:

```
[OBSERVER] Nessuna literature search da 3 cicli. Stale knowledge risk.
Fonti consigliate: ${domainConfig.literature.primary.join(', ')}
```

**Cosa conta come "literature search":**
- Uso di un MCP server di letteratura (Layer 1)
- Invocazione di una K-Dense database skill (Layer 2)
- Query a un Local RAG (Layer 3)
- WebSearch con termini scientifici (rilevato via pattern matching)
- Lettura esplicita di un paper (DOI/PMID nel tool_input)

Il PostToolUse hook intercetta queste azioni e le registra automaticamente nella tabella `literature_searches`.

### 10A.9 Data Discovery Pipeline (download → analisi → serendipity)

**QUESTA CAPACITA' E' FONDAMENTALE E INVARIATA IN v6.0.**

Nel lavoro CRISPR, l'Experimenter ha:
- Scaricato interi dataset (GUIDE-seq, CHANGE-seq, CIRCLE-seq, TrueOT, CRISPRoffT)
- Scritto script Python custom per ogni analisi (preprocessing, feature extraction, model training)
- Calibrato conformal prediction sets con split strategici
- Scoperto pattern inattesi (serendipity) che hanno generato nuove direzioni di ricerca

Questa pipeline resta intatta. Il Literature Engine la COMPLEMENTA, non la sostituisce:

```
Literature Engine              Data Discovery Pipeline
(Layer 1-3)                    (Experimenter agent)
     │                              │
     ├─ Prior art found ──────────→ │ Informa la direction
     ├─ Dataset reference ────────→ │ Triggera download
     ├─ Methodology paper ────────→ │ Informa lo script design
     │                              │
     │                              ├─ Risultati → Serendipity Scanner
     │                              ├─ Anomalie → Nuove literature searches
     └─ Cross-reference ←──────────┘
```

Il Literature Engine e la Data Discovery Pipeline formano un **feedback loop**: la letteratura informa l'analisi dei dati, e l'analisi dei dati genera nuove domande per la letteratura.

**Esempio concreto (CRISPR workflow ricostruito):**
1. L-1+ search su PubMed/bioRxiv → trova Lazzarotto 2020 (CHANGE-seq protocol)
2. Experimenter scarica il dataset raw da supplementary materials
3. Experimenter scrive script Python per preprocessing e feature extraction
4. Analisi trova distribuzione inattesa → Serendipity Scanner flagga (score 14)
5. Nuova literature search → trova Fu 2022 → pattern gia' documentato → claim killed early
6. Risparmio: 2 cicli OTAE evitati grazie al feedback loop

**Per genomica e altri domini data-intensive:**
La capacita' di scaricare dataset da GEO, SRA, Materials Project, Pangaea, etc. e scrivere script Python di analisi e' la stessa usata per CRISPR. Il Literature Engine aggiunge solo il contesto (quali dataset esistono, cosa e' gia' stato analizzato) — l'analisi resta in mano all'Experimenter con piena liberta' di coding.

### 10A.10 Schema DB per il Literature Engine

Tabella aggiunta allo schema (Sezione 5):

```sql
-- ═══════════════════════════════════════════════════════
-- LITERATURE: Search tracking per L-1+ enforcement
-- ═══════════════════════════════════════════════════════

CREATE TABLE literature_searches (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    session_id TEXT NOT NULL,
    query TEXT NOT NULL,
    sources TEXT NOT NULL,         -- JSON array: ["pubmed", "biorxiv"]
    results_count INTEGER,
    relevant_count INTEGER,
    key_papers TEXT,               -- JSON array di DOI/PMID/titoli
    search_layer TEXT NOT NULL,    -- MCP / SKILL / RAG / MANUAL / WEBSEARCH
    gate_context TEXT,             -- L1_PRE_DIRECTION / OTAE_CONTINUOUS / AD_HOC
    timestamp TEXT NOT NULL,
    FOREIGN KEY (session_id) REFERENCES sessions(id)
);
CREATE INDEX idx_lit_session ON literature_searches(session_id);
CREATE INDEX idx_lit_layer ON literature_searches(search_layer);
```

### 10A.11 Costo e Trade-offs

| Aspetto | Valutazione |
|---|---|
| **Token cost L-1+ enforcement** | ~50 token per check (query DB). Trascurabile. |
| **Token cost context injection** | ~100 token per le fonti raccomandate nel SessionStart. Accettabile. |
| **MCP server overhead** | Dipende dal server. Tipicamente 1-5s per query. Accettabile per literature search. |
| **literature-registry.json size** | ~15-20 KB per 105+ entries. Trascurabile. |
| **Manutenzione registro** | Richiede aggiornamento manuale quando nascono nuovi database/MCP server. Mitigato: il registro e' un JSON versionato, aggiornamenti via PR. |
| **Database con abbonamento** | ~40% dei database richiede abbonamento istituzionale. L'agent puo' usare solo quelli free/API disponibili. Il registro indica l'accesso per ogni database. |

---

## 11. Cosa Manteniamo (invarianti da v5.0 + v5.5)

### 11.1 Da v5.0 IUDEX (W1-W10 del Blueprint v5.5)

| ID | Cosa | Status v6.0 |
|----|------|------------|
| W1 | Guide-held-out splitting | **INVARIATO** |
| W2 | Multiple seeds (5x5) | **INVARIATO** |
| W3 | Falsificazione aggressiva | **INVARIATO** |
| W4 | Agent teams paralleli | **POTENZIATO** — permission enforcement |
| W5 | CQR come follow-up costruttivo | **INVARIATO** |
| W6 | Wilson confidence intervals | **INVARIATO** |
| W7 | SFI + BFP + R3 Judge | **POTENZIATO** — SFI usa calibration data |
| W8 | Schema-validated gates | **INVARIATO** — stessi 12 schema |
| W9 | 10 Leggi Immutabili | **INVARIATO** — testo identico |
| W10 | Salvagente Rule | **POTENZIATO** — seeds persistono cross-sessione |

### 11.2 Da v5.5 ORO (5 sottosistemi + 5 potenziamenti)

| Sottosistema | v5.5 (Prompt) | v6.0 (Codice) |
|-------------|--------------|---------------|
| VibeBrAIn | MCP server Python + ChromaDB | **SQLite + sqlite-vec nel plugin** (stesso concetto, impl diversa) |
| Silent Observer | Daemon Python thread | **Check periodico nel PostToolUse hook** (no daemon separato) |
| Research Spine | Istruzione "logga nel SPINE.md" | **Auto-log nel DB + export SPINE.md** |
| DQ Gate Engine | Pseudo-codice Python | **Gate enforcement nel PostToolUse con exit code 2** |
| SSOT + Auto-Gen | Scripts Python | **Sync check nel PostToolUse hook** |
| R2 INLINE | 7° modo nel prompt | **INVARIATO** (resta prompt-level, appropriato) |
| Literature Gate L-1 | Gate nel prompt | **POTENZIATO** — L-1+ con enforcement (hook exit code 2 pre-direction, observer durante OTAE). Vedi Sezione 10A. |
| Feature Validation | Parte di DQ1 | **Enforcement nel PostToolUse** |
| Design Compliance DC0 | Gate nel prompt | **Enforcement nel PostToolUse** |
| Data Dictionary DD0 | Gate nel prompt | **INVARIATO** (documenting e' attivita' dell'agent) |

### 11.3 Pre-planned items v5.5 (dal Roadmap v5.0)

| ID | Feature | Status v6.0 |
|----|---------|------------|
| R5.5-01 | Calibration Log | **IMPLEMENTATO** — tabella `calibration_log` nel DB |
| R5.5-02 | Golden Claims Test Suite | **INVARIATO** — 12 test cases |
| R5.5-03 | Cross-Model Audit Protocol | **INVARIATO** — opzionale |
| R5.5-04 | Anti-Gaming Metrics | **POTENZIATO** — tracked nel DB (`r2_reviews` table) |
| R5.5-05 | Dataset Hash (SHA-256) | **INVARIATO** — in spine entries |

### 11.4 Deferred items v6.0 (dal Roadmap v5.0)

| ID | Feature | Status v6.0 |
|----|---------|------------|
| R6.0-01 | Confidence Calibration (Brier/ECE) | **IMPLEMENTABILE** — calibration_log ha i dati, calcolo in `context-builder.js` |
| R6.0-02 | R-C Collinearity Resolution | **DEFERRED a v7.0** — serve piu' data empirica |
| R6.0-03 | Threat Model + Security Gate | **PARZIALMENTE COPERTO** — permission engine e' un security gate base |
| R6.0-04 | Log-Odds / Bayes Factor Confidence | **DEFERRED a v7.0** |
| R6.0-05 | W3C PROV Provenance | **DEFERRED** — spine_entries + claim_events sono provenance sufficiente |

---

## 12. Honest Limitations (cosa v6.0 NON puo' fare)

| Sottosistema | Limitazione | Mitigazione |
|-------------|------------|------------|
| **PostToolUse enforcement** | Puo' bloccare DOPO che il tool e' stato eseguito, non PRIMA. Se l'agent fa `Write CLAIM-LEDGER.md`, il file e' gia' scritto quando il hook controlla. | Per Write/Edit: il hook puo' REVERTIRE il cambiamento se il check fallisce (read file, restore). Per Bash: non c'e' revert automatico. |
| **Agent role identification** | In SOLO mode, il ruolo e' inferito dal prompt — puo' essere sbagliato. | In TEAM mode, il ruolo e' esplicito. In SOLO mode, fallback conservative: treat as researcher (permessi ampi). |
| **sqlite-vec vs Chroma** | sqlite-vec ha meno funzionalita' (no metadata filtering nativo, no hybrid search built-in). | Metadata filtering fatto in SQL prima del vec search. Hybrid: SQL full-text + vec cosine combinati manualmente. Per il nostro use case e' sufficiente. |
| **Embedding model** | all-MiniLM-L6-v2 ha embedding a 384 dim. Potrebbe perdere sfumature scientifiche. | Per ricerca semantica di contesto (non per classificazione), 384 dim sono sufficienti. Se necessario, upgrade a un modello scientifico (es. specter2) in futuro. |
| **Gate soglie hardcoded** | Le soglie DQ sono specifiche per dominio. Per un nuovo dominio, servono soglie nuove. | domain-config.json permette override. Il plugin legge il config. |
| **Literature Registry statico** | literature-registry.json richiede aggiornamento manuale. Nuovi database/MCP server non vengono scoperti automaticamente. | Registro versionato, aggiornamenti via PR. L'agent puo' comunque cercare fonti non nel registro — il registro e' una guida, non un vincolo. |
| **~40% database a pagamento** | Molte fonti nella tassonomia richiedono abbonamento istituzionale. L'agent non puo' accedere ai full-text. | Il registro indica l'accesso per ogni database. L'agent usa fonti free/API disponibili e segnala quando serve accesso istituzionale. |
| **No Web UI** | Nessun dashboard visuale come claude-mem. | CLI-first. I dati sono ispezionabili via SQL diretto: `sqlite3 ~/.vibe-science/db/vibe-science.db`. In futuro, un opzionale `ui/dashboard.html` per ispezione (non prioritario). |
| **Narrative summary senza LLM** | Il template-based summary e' meno eloquente di un summary generato da LLM. | Ma e' deterministico, zero costo, e non hallucina. I dati sono strutturati — non serve un LLM per riassumerli. |

### La regola anti-theatre (aggiornata da v5.5)

| Sottosistema | Bypassabile via prompt? | v5.5 | v6.0 |
|-------------|------------------------|------|------|
| DQ Gates (soglie) | No | Architecture-enforced | **Architecture-enforced (hook exit code 2)** |
| SSOT sync_check | No | Architecture-enforced | **Architecture-enforced (hook)** |
| Observer | No | Architecture-enforced (daemon) | **Architecture-enforced (periodic in-hook check)** |
| VibeBrAIn recall | **v5.5: SI** | Bypassabile | **v6.0: NO — recall e' nel UserPromptSubmit hook** |
| Research Spine | **v5.5: SI** | Bypassabile | **v6.0: NO — auto-log nel PostToolUse hook** |
| R2 INLINE | Parzialmente | Parzialmente | **Parzialmente** — in SOLO mode resta auto-review |
| DD0 Gate | **v5.5: SI** | Bypassabile | **Parzialmente** — hook puo' controllare se colonne sono documentate nel DB |
| L-1+ Literature Gate | **v5.5: SI** | Bypassabile | **v6.0: PARZIALMENTE** — pre-direction e' BLOCKING (hook exit 2), durante OTAE e' observer WARNING |
| TEAM Permissions | N/A | Non esisteva | **v6.0: NO — hook exit code 2 blocca** |

**Miglioramento:** Da 3/8 fully enforced (v5.5) a **6/9 fully enforced (v6.0)**.
I 2.5 rimanenti (R2 INLINE in SOLO, DD0 contenuto, agent role in SOLO) richiederebbero modifiche al core di Claude Code — fuori dal nostro controllo. Sono mitigati al meglio possibile.

---

## 13. Differenze Strutturali Cumulative

### v5.0 → v5.5 → v6.0

| Aspetto | v5.0 IUDEX | v5.5 ORO | v6.0 NEXUS |
|---------|-----------|---------|-----------|
| **Tipo prodotto** | Skill | Skill | **Plugin** |
| Gate totali | 27 (8 schema) | 34 (11 schema) | **34** (11 schema, **enforced via code**) |
| Schema totali | 9 | 12 | **12** |
| Protocolli totali | 21 | 29 | **29** (invariati, in `skill/`) |
| R2 modi | 6 | 7 (+INLINE) | **7** |
| Enforcement | Prompt-level | Prompt-level + 3 architecture | **8/8 via hooks** |
| Memoria | File flat | File flat + ChromaDB (progettato) | **SQLite + sqlite-vec (implementato)** |
| Cross-sessione | Nessuna | VibeBrAIn (progettato) | **DB persistente + narrative summaries** |
| Auto-miglioramento | Nessuno | Nessuno | **R2 calibration, researcher patterns, SFI targeting** |
| TEAM permissions | Convenzione | Convenzione | **Hook-enforced (exit code 2)** |
| Dipendenze | Nessuna | chromadb, sentence-transformers, Python | **Bun, sqlite-vec, all-MiniLM-L6-v2 (no Python)** |
| Installazione | Copia file | Copia file + MCP server setup | **3 comandi (/plugin)** |
| Logbook | Opzionale | Istruzione-based (SPINE.md) | **Auto-log nel DB** |
| Serendipity seeds | Muoiono a fine sessione | Muoiono a fine sessione | **Persistono nel DB** |
| Dimensione | ~40 file | ~55 file | **~70 file (plugin/ + skill/ + blueprints/)** |
| Dipendenze disk | 0 | ~200 MB (Chroma+Python) | **~120 MB (Bun+model)** |

---

## 14. Implementation Priority Matrix

### Fase A: Plugin Skeleton (DO FIRST)

| # | Cosa | Effort | Impact |
|---|------|--------|--------|
| T-01 | plugin.json + hooks.json (manifest e struttura) | Basso | Critico |
| T-02 | setup.js (auto-install Bun, SQLite, directories) | Medio | Critico |
| T-03 | schema.sql (database completo) | Medio | Critico |
| T-04 | session-start.js (context injection base) | Medio | Alto |
| T-05 | post-tool-use.js (auto-log + gate stub) | Alto | Critico |
| T-06 | stop.js (narrative summary + claim check) | Medio | Alto |

**Deliverable Fase A:** Plugin funzionante che auto-logga, genera narrative summaries, e inietta contesto.

### Fase B: Enforcement (DO SECOND)

| # | Cosa | Effort | Impact |
|---|------|--------|--------|
| T-07 | gate-engine.js (DQ1-DQ4 enforcement con exit code 2) | Alto | Critico |
| T-08 | permission-engine.js (TEAM mode permissions) | Medio | Alto |
| T-09 | prompt-submit.js (agent identification + auto recall) | Medio | Alto |
| T-10 | Observer checks nel PostToolUse | Medio | Alto |

**Deliverable Fase B:** Gate enforcement reale, TEAM permissions, recall automatico.

### Fase C: Intelligence (DO THIRD)

| # | Cosa | Effort | Impact |
|---|------|--------|--------|
| T-11 | worker-embed.js (daemon Bun per embedding async) | Alto | Alto |
| T-12 | vec-search.js (sqlite-vec wrapper) | Medio | Alto |
| T-13 | context-builder.js (progressive disclosure) | Medio | Alto |
| T-14 | R2 auto-calibration (loadR2CalibrationData) | Medio | Medio |
| T-15 | Researcher pattern recognition | Medio | Medio |
| T-16 | Seed survival cross-sessione | Basso | Medio |

**Deliverable Fase C:** Ricerca semantica, progressive disclosure, auto-calibration loop.

### Fase D: Integration + Verification

| # | Cosa | Effort | Impact |
|---|------|--------|--------|
| T-17 | Copia skill/ da v5.5 (invariato) | Basso | Critico |
| T-18 | Copia blueprints/ | Basso | Medio |
| T-19 | domain-config.json per CRISPR | Basso | Medio |
| T-20 | literature-registry.json + L-1+ gate enforcement | Medio | Alto |
| T-21 | MCP server configuration per letteratura | Basso | Medio |
| T-22 | README.md + package.json | Medio | Medio |
| T-23 | Forensic Checklist v6.0 (Sezione 15) | Alto | Critico |
| T-24 | Golden Claims Test against plugin | Alto | Critico |

**Deliverable Fase D:** Plugin completo, testato, documentato.

### Stima

- **Fase A:** 2-3 sessioni (skeleton + hooks base)
- **Fase B:** 2-3 sessioni (enforcement)
- **Fase C:** 3-4 sessioni (intelligence + embedding)
- **Fase D:** 1-2 sessioni (integration + verification)
- **Totale: 8-12 sessioni con agent teams**
- **Nuove righe stimate:** ~4,000 (codice JS) + ~1,800 (skill invariata) + ~2,000 (documentation)

---

## 15. Forensic Checklist v6.0

### A. Hard-Fail Criteria (v5.0 + v5.5 invariati)

- **A1.** Tutti i 34 gate (27 v5.0 + 7 v5.5) presenti e funzionanti?
- **A2.** I 12 schema JSON invariati e read-only?
- **A3.** Le 10 Leggi Immutabili invariate? (testo identico)
- **A4.** SFI + BFP + R3 + SVG invariati per FORCED reviews?
- **A5.** Circuit Breaker + DISPUTED + S5 Poison Pill invariati?
- **A6.** Permission Model invariato come specifica? (ora ENFORCED via codice)
- **A7.** DQ Gates v5.5 (DQ1-DQ4, DC0, DD0, L-1) tutti presenti?
- **A7b.** Literature Engine (Sezione 10A) integrato? literature-registry.json e domain-config.json con sezione literature documentati?
- **A8.** R2 INLINE (7° modo) presente in skill/protocols/reviewer2-ensemble.md?

### B. Plugin Infrastructure (NUOVI)

- **B1.** plugin.json presente e valido?
- **B2.** hooks.json con 5 lifecycle hooks + 1 setup?
- **B3.** setup.js: auto-install Bun, crea directories, inizializza DB?
- **B4.** schema.sql: tutte le tabelle definite (sessions, spine_entries, claim_events, r2_reviews, serendipity_seeds, gate_checks, observer_alerts, calibration_log, prompt_log, vec_memories, embed_queue)?
- **B5.** sqlite-vec extension caricabile e funzionante?
- **B6.** Worker embedding: daemon Bun avviabile e stoppabile?
- **B7.** Fallback graceful: sistema funziona ANCHE senza DB (solo file flat)?

### C. Hook Enforcement (NUOVI)

- **C1.** PostToolUse: exit code 2 blocca effettivamente l'agent?
- **C2.** PostToolUse: DQ4 sync check su FINDINGS.md funzionante?
- **C3.** PostToolUse: Gate enforcement su CLAIM-LEDGER funzionante?
- **C4.** PostToolUse: Permission enforcement in TEAM mode funzionante?
- **C5.** PostToolUse: Auto-log in spine_entries per azioni significative?
- **C6.** PostToolUse: Observer checks periodici (ogni 10 tool uses)?
- **C7.** Stop: Narrative summary generato correttamente?
- **C8.** Stop: Claim review check blocca se claims non reviewate?
- **C9.** SessionStart: Context injection < 1000 tokens?
- **C10.** UserPromptSubmit: Auto-recall semantico funzionante?

### D. Auto-Calibration (NUOVI)

- **D1.** R2 calibration data caricato a SessionStart?
- **D2.** R2 weakness hint iniettato nel context?
- **D3.** SFI targeting basato su catch rates storici?
- **D4.** Researcher error patterns tracked?
- **D5.** Serendipity seeds persistono cross-sessione?
- **D6.** Calibration log (R5.5-01) attivo nel DB?

### E. Progressive Disclosure (NUOVI)

- **E1.** Layer 1 (state) < 200 tokens?
- **E2.** Layer 2 (semantic + calibration + alerts) < 500 tokens?
- **E3.** Layer 1+2 totale < 1000 tokens?
- **E4.** Full detail disponibile on-demand?

### F. TEAM Mode Permissions (NUOVI)

- **F1.** R2 BLOCKED da scrivere CLAIM-LEDGER?
- **F2.** Judge BLOCKED da modificare R2 reports?
- **F3.** Serendipity BLOCKED da scrivere CLAIM-LEDGER?
- **F4.** Researcher ALLOWED ovunque tranne R2 reports?
- **F5.** Permission check non blocca in SOLO mode? (fail open per safety)

### G. Skill Integrity (invarianza)

- **G1.** skill/SKILL.md identico a v5.5 ORO?
- **G2.** skill/CLAUDE.md identico a v5.5 ORO?
- **G3.** skill/protocols/ — tutti 29 file presenti?
- **G4.** skill/schemas/ — tutti 12 file presenti e READ-ONLY?
- **G5.** skill/gates/gates.md — 34 gate elencati?
- **G6.** skill/assets/ — fault-taxonomy.yaml e judge-rubric.yaml presenti?

### H. Documentation

- **H1.** README.md con istruzioni installazione (3 comandi)?
- **H2.** blueprints/ con tutti i blueprint referenziati?
- **H3.** domain-config.json documentato?
- **H4.** package.json con version 6.0.0?

### Scoring

- **Sezione A (Hard-Fail):** TUTTI devono passare. Qualsiasi fail = v6.0 NON SHIPPABLE
- **Sezioni B-F (Forensic):** Target >= 80%. < 60% = "plugin theatre" (infrastruttura senza enforcement)
- **Sezione G (Invarianza):** TUTTI devono passare (la skill non puo' degradare)
- **Sezione H (Documentation):** Target >= 75%

---

## 16. Roadmap v7.0

Items identificati durante la progettazione v6.0 ma premature per questa versione:

| ID | Feature | Perche' deferred |
|----|---------|-----------------|
| R7.0-01 | **Confidence Calibration (Brier/ECE)** | Serve >>50 claims calibrati. v6.0 raccoglie i dati, v7.0 li usa. |
| R7.0-02 | **R-C Collinearity → External Validation** | Merge R e C in un singolo componente. Serve data empirica. |
| R7.0-03 | **Cross-Model R2 via MCP** | Plugin potrebbe esporre un MCP tool che invoca un secondo modello per R2. Richiede architettura MCP server. |
| R7.0-04 | **Web Dashboard** | Opzionale `ui/dashboard.html` per ispezione visuale del DB. Non prioritario per CLI workflow. |
| R7.0-05 | **Scientific Embedding Model** | Sostituire all-MiniLM-L6-v2 con specter2 o un modello specializzato per testo scientifico. |
| R7.0-06 | **Plugin Marketplace Publication** | Pubblicare su marketplace Claude Code per installazione one-command. |
| R7.0-07 | **PreToolUse Hook** | Se Claude Code aggiunge un hook PRIMA dell'esecuzione del tool (non solo POST), i permessi possono bloccare PRIMA della scrittura, non dopo. Eliminaria il limite piu' importante di v6.0. |

---

## Appendice A: Mapping Errore → Fix → Enforcement Level

| Errore | Root Cause | Fix v5.5 | Fix v6.0 | Enforcement |
|--------|-----------|---------|---------|-------------|
| M1 | RC4 | L-1 pre-check | L-1 (invariato, prompt) | Prompt |
| M2 | RC7 | DC0 + Observer | DC0 (hook) + Observer (hook) | **Code** |
| M3 | RC1 | DQ1 + DQ2 | DQ1 + DQ2 (hook exit 2) | **Code** |
| M4 | RC3 | Feature Validation in DQ1 | DQ1 (hook exit 2) | **Code** |
| M5 | RC3 | Cross-check in DQ1 | DQ1 (hook exit 2) | **Code** |
| M6 | RC2 | SSOT + DQ4 | DQ4 sync check (hook exit 2) | **Code** |
| M7 | RC3 | DD0 + DQ1 | DD0 (prompt) + DQ1 (hook exit 2) | **Code + Prompt** |
| M8 | RC1 | DQ2 | DQ2 (hook exit 2) | **Code** |
| M9 | RC5 | R2 INLINE + DQ4 | R2 INLINE (prompt) + DQ4 (hook) | **Code + Prompt** |
| M10 | RC5 | R2 INLINE + L-1 | R2 INLINE (prompt) + L-1 (prompt) | Prompt |
| M11 | RC6 | Research Spine | Auto-log in PostToolUse hook | **Code** |
| M12 | RC2 | SSOT + Observer | DQ4 (hook) + Observer (hook) | **Code** |

**Copertura enforcement:**
- v5.5: 3/12 code-enforced, 9/12 prompt-enforced
- **v6.0: 10/12 code-enforced, 2/12 prompt-enforced** (M1, M10 restano prompt perche' sono attivita' cognitive dell'agent)

---

## Appendice B: Pattern Adottati da claude-mem v10.3.1

| Pattern claude-mem | Adattamento v6.0 | Differenza chiave |
|-------------------|------------------|-------------------|
| 5 lifecycle hooks | 5 lifecycle hooks | Identica struttura (Setup, SessionStart, UserPromptSubmit, PostToolUse, Stop) |
| Progressive disclosure (3-layer) | Progressive disclosure (3-layer) | Stessi livelli: index → context → detail. Token budget diverso (~700 vs ~3000) |
| Narrative summary at Stop | Narrative summary at Stop | Senza LLM (template-based vs SDK Agent spawn) |
| SQLite + Chroma | **SQLite + sqlite-vec** | Single DB, ~200x piu' leggero |
| Express worker (port 37777) | **Bun daemon (embedding only)** | No HTTP server, no Web UI. Solo embedding async. |
| SDK Agent (spawn Claude) | **Non adottato** | Troppo costoso/lento per summary. Template e' sufficiente. |
| Web UI viewer | **Non adottato** | CLI-first. SQL diretto per ispezione. |
| MCP search tools (5) | **Non adottato direttamente** | Ricerca via hook context injection, non via MCP. Possibile aggiunta futura. |
| Privacy tags (`<private>`) | **Non adottato** | Non necessario per ricerca scientifica (dati pubblici) |
| Context configuration | domain-config.json | Configurazione per dominio, non per privacy |

---

## Appendice C: Pattern Adottati da myBrAIn v1.1

| Pattern myBrAIn | Adattamento v6.0 | Differenza |
|-----------------|------------------|-----------|
| RECALL→CODE→MEMORIZE | RECALL→RESEARCH→MEMORIZE | Stesso pattern. RECALL ora nel hook (enforced), non nel prompt. |
| Conflict detection (cosine < 0.5) | Conflict detection (sqlite-vec) | Stessa logica, diverso backend. |
| SilentObserver (daemon thread) | Observer checks in PostToolUse hook | No daemon separato. Check periodici (ogni 10 tool uses). |
| ChromaDB vector store | sqlite-vec | ~200x piu' leggero, stesso risultato per il nostro use case. |
| Deterministic session ID (SHA-256) | Session UUID | Diverso: UUID e' piu' semplice. Project path e RQ sono metadata. |
| Admin Dashboard (Streamlit) | **Non adottato** | Over-engineering per CLI workflow. |
| Docker support | **Non adottato** | Overhead non giustificato. |

---

## Appendice D: Decisioni Architetturali e Razionale

### Perche' Plugin e non Skill?

Una skill puo' dire "controlla le feature" ma non puo' bloccare l'agent se non lo fa. Un plugin con PostToolUse hook puo' restituire exit code 2 e IMPEDIRE all'agent di procedere. Questo e' il salto fondamentale: da "per favore fai" a "non puoi non fare."

### Perche' sqlite-vec e non Chroma?

1. **Dimensione**: sqlite-vec ~1 MB vs Chroma ~200 MB
2. **Dipendenze**: sqlite-vec e' una SQLite extension (C), Chroma richiede Python + sentence-transformers
3. **Single DB**: tutto in un database SQLite, nessuna coordinazione
4. **Sufficienza**: per ~1000 memorie per progetto, sqlite-vec e' piu' che sufficiente. Chroma scala meglio per milioni di documenti — non il nostro caso.

### Perche' Bun e non Node.js puro?

1. **SQLite nativo**: Bun ha `bun:sqlite` built-in, molto veloce
2. **Worker leggero**: Bun come runtime per il daemon di embedding e' piu' leggero di Node
3. **claude-mem lo usa**: precedente consolidato nell'ecosistema Claude Code

### Perche' narrative summary senza LLM?

1. **Costo zero**: nessuna API call per il summary
2. **Deterministico**: stesso input = stesso output, sempre
3. **Veloce**: template rendering vs spawn Claude subprocess
4. **Non hallucina**: i dati sono strutturati nel DB, il template li formatta
5. **claude-mem usa SDK Agent**: spawn di un subprocess Claude per compressione. Costoso, lento, e aggiunge complessita'. Per dati strutturati e' overkill.

### Perche' non un MCP server come v5.5 progettava?

v5.5 progettava VibeBrAIn come MCP server standalone (come myBrAIn). v6.0 integra tutto nei hooks del plugin perche':
1. **Un MCP server e' un processo separato** — bisogna avviarlo, gestirlo, debuggarlo
2. **I hooks sono nativi** — eseguiti dal framework Claude Code, nessun processo extra
3. **Il database e' condiviso** — hooks e query usano lo stesso SQLite, no coordinamento
4. **L'embedding e' l'unica operazione async** — solo quella richiede un worker separato

Se in futuro servisse un'interfaccia MCP (es. per cross-model R2 o per tool search), sara' un'aggiunta opzionale, non il core.

### Perche' mantenere la skill invariata?

La skill contiene la METODOLOGIA: come ragionare, come fare R2 review, come applicare gates, come gestire serendipity. Questa e' saggezza accumulata in 6 versioni e 21 sprint CRISPR. Riscriverla nel plugin sarebbe:
1. **Rischio di regressione**: perdere sfumature nei prompt
2. **Rigidita'**: codice e' meno adattabile di prompt per ragionamento
3. **Inutile**: i prompt funzionano bene per guidare il ragionamento — e' l'enforcement che manca

Il plugin aggiunge l'enforcement che la skill non puo' avere. La skill resta la mente. Il plugin diventa il corpo.

---

*Blueprint v6.0 NEXUS completato: 20 febbraio 2026*
*Versione: 1.1 (aggiunta Sezione 10A: Literature Engine)*
*Input: Blueprint v5.0 IUDEX, Blueprint v5.5 ORO, Blueprint ORO-PHOTONICS, claude-mem v10.3.1, myBrAIn v1.1, Post-Mortem CRISPR, Brainstorming Session 2026-02-20*
*Prossimo passo: implementazione Fase A (Plugin Skeleton — 6 task)*
